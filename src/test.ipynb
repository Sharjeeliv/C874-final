{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc650e25",
   "metadata": {},
   "source": [
    "**Collaborative Filtering Approaches**\n",
    "1. Memory-based:    ItemKNN\n",
    "2. Model-based:     BPR, LightGCN\n",
    "3. Context-based:   FM, DeepFM, WideDeep\n",
    "\n",
    "**Content-based Approaches:** TFIDF (Cornac Models)\n",
    "\n",
    "**Knowledge-based Approaches:** KGCN, KGAT, KGIN\n",
    "\n",
    "**Hybrid Systems:** NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9fe9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jul 01:39    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = C:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\Lib\\site-packages\\recbole\\config\\../dataset_example/ml-100k\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = True\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = None\n",
      "relation_kg_num_interval = None\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "21 Jul 01:39    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "21 Jul 01:39    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "21 Jul 01:39    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "21 Jul 01:39    INFO  BPR(\n",
      "  (user_embedding): Embedding(944, 64)\n",
      "  (item_embedding): Embedding(1683, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 168128\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "21 Jul 01:39    INFO  epoch 0 training [time: 0.58s, train loss: 27.7207]\n",
      "21 Jul 01:39    INFO  epoch 0 evaluating [time: 0.33s, valid_score: 0.022600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.0075    mrr@10 : 0.0226    ndcg@10 : 0.0094    hit@10 : 0.0795    precision@10 : 0.0085\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 1 training [time: 0.48s, train loss: 27.6127]\n",
      "21 Jul 01:39    INFO  epoch 1 evaluating [time: 0.31s, valid_score: 0.059900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.0177    mrr@10 : 0.0599    ndcg@10 : 0.0254    hit@10 : 0.176    precision@10 : 0.0223\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 2 training [time: 0.47s, train loss: 27.2250]\n",
      "21 Jul 01:39    INFO  epoch 2 evaluating [time: 0.31s, valid_score: 0.162300]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.0609    mrr@10 : 0.1623    ndcg@10 : 0.0814    hit@10 : 0.3892    precision@10 : 0.068\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 3 training [time: 0.48s, train loss: 25.6884]\n",
      "21 Jul 01:39    INFO  epoch 3 evaluating [time: 0.31s, valid_score: 0.238300]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.099    mrr@10 : 0.2383    ndcg@10 : 0.1225    hit@10 : 0.5069    precision@10 : 0.0931\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 4 training [time: 0.47s, train loss: 22.1513]\n",
      "21 Jul 01:39    INFO  epoch 4 evaluating [time: 0.31s, valid_score: 0.253000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1137    mrr@10 : 0.253    ndcg@10 : 0.1364    hit@10 : 0.5419    precision@10 : 0.1034\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 5 training [time: 0.47s, train loss: 18.0216]\n",
      "21 Jul 01:39    INFO  epoch 5 evaluating [time: 0.32s, valid_score: 0.270900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1212    mrr@10 : 0.2709    ndcg@10 : 0.144    hit@10 : 0.5684    precision@10 : 0.1043\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 6 training [time: 0.47s, train loss: 15.4003]\n",
      "21 Jul 01:39    INFO  epoch 6 evaluating [time: 0.32s, valid_score: 0.280800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1258    mrr@10 : 0.2808    ndcg@10 : 0.1488    hit@10 : 0.5716    precision@10 : 0.1056\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 7 training [time: 0.47s, train loss: 14.1378]\n",
      "21 Jul 01:39    INFO  epoch 7 evaluating [time: 0.32s, valid_score: 0.293800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1329    mrr@10 : 0.2938    ndcg@10 : 0.1556    hit@10 : 0.5896    precision@10 : 0.1084\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 8 training [time: 0.46s, train loss: 13.3550]\n",
      "21 Jul 01:39    INFO  epoch 8 evaluating [time: 0.29s, valid_score: 0.306900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.136    mrr@10 : 0.3069    ndcg@10 : 0.1609    hit@10 : 0.5949    precision@10 : 0.1086\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 9 training [time: 0.46s, train loss: 12.7709]\n",
      "21 Jul 01:39    INFO  epoch 9 evaluating [time: 0.29s, valid_score: 0.313900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1432    mrr@10 : 0.3139    ndcg@10 : 0.1668    hit@10 : 0.6151    precision@10 : 0.1128\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 10 training [time: 0.46s, train loss: 12.3069]\n",
      "21 Jul 01:39    INFO  epoch 10 evaluating [time: 0.32s, valid_score: 0.318100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1516    mrr@10 : 0.3181    ndcg@10 : 0.1737    hit@10 : 0.6235    precision@10 : 0.1174\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 11 training [time: 0.48s, train loss: 11.8370]\n",
      "21 Jul 01:39    INFO  epoch 11 evaluating [time: 0.31s, valid_score: 0.323000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1625    mrr@10 : 0.323    ndcg@10 : 0.1813    hit@10 : 0.6458    precision@10 : 0.1233\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 12 training [time: 0.48s, train loss: 11.3931]\n",
      "21 Jul 01:39    INFO  epoch 12 evaluating [time: 0.31s, valid_score: 0.324600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1655    mrr@10 : 0.3246    ndcg@10 : 0.1848    hit@10 : 0.649    precision@10 : 0.1262\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 13 training [time: 0.48s, train loss: 11.0161]\n",
      "21 Jul 01:39    INFO  epoch 13 evaluating [time: 0.32s, valid_score: 0.328700]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1688    mrr@10 : 0.3287    ndcg@10 : 0.1881    hit@10 : 0.6575    precision@10 : 0.13\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 14 training [time: 0.48s, train loss: 10.6968]\n",
      "21 Jul 01:39    INFO  epoch 14 evaluating [time: 0.31s, valid_score: 0.327800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1717    mrr@10 : 0.3278    ndcg@10 : 0.1909    hit@10 : 0.6585    precision@10 : 0.1331\n",
      "21 Jul 01:39    INFO  epoch 15 training [time: 0.51s, train loss: 10.3347]\n",
      "21 Jul 01:39    INFO  epoch 15 evaluating [time: 0.32s, valid_score: 0.329900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1738    mrr@10 : 0.3299    ndcg@10 : 0.1918    hit@10 : 0.6702    precision@10 : 0.1343\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 16 training [time: 0.47s, train loss: 10.0525]\n",
      "21 Jul 01:39    INFO  epoch 16 evaluating [time: 0.34s, valid_score: 0.331100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1778    mrr@10 : 0.3311    ndcg@10 : 0.1931    hit@10 : 0.6755    precision@10 : 0.1361\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 17 training [time: 0.47s, train loss: 9.7565]\n",
      "21 Jul 01:39    INFO  epoch 17 evaluating [time: 0.31s, valid_score: 0.334300]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1799    mrr@10 : 0.3343    ndcg@10 : 0.1967    hit@10 : 0.684    precision@10 : 0.138\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 18 training [time: 0.47s, train loss: 9.4517]\n",
      "21 Jul 01:39    INFO  epoch 18 evaluating [time: 0.30s, valid_score: 0.332600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1817    mrr@10 : 0.3326    ndcg@10 : 0.1965    hit@10 : 0.6946    precision@10 : 0.1387\n",
      "21 Jul 01:39    INFO  epoch 19 training [time: 0.46s, train loss: 9.3639]\n",
      "21 Jul 01:39    INFO  epoch 19 evaluating [time: 0.30s, valid_score: 0.330600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1823    mrr@10 : 0.3306    ndcg@10 : 0.1968    hit@10 : 0.6861    precision@10 : 0.1392\n",
      "21 Jul 01:39    INFO  epoch 20 training [time: 0.46s, train loss: 9.1683]\n",
      "21 Jul 01:39    INFO  epoch 20 evaluating [time: 0.32s, valid_score: 0.333600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1832    mrr@10 : 0.3336    ndcg@10 : 0.1988    hit@10 : 0.6914    precision@10 : 0.1411\n",
      "21 Jul 01:39    INFO  epoch 21 training [time: 0.48s, train loss: 8.9459]\n",
      "21 Jul 01:39    INFO  epoch 21 evaluating [time: 0.32s, valid_score: 0.332800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1827    mrr@10 : 0.3328    ndcg@10 : 0.1995    hit@10 : 0.685    precision@10 : 0.1422\n",
      "21 Jul 01:39    INFO  epoch 22 training [time: 0.48s, train loss: 8.7272]\n",
      "21 Jul 01:39    INFO  epoch 22 evaluating [time: 0.31s, valid_score: 0.341200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1838    mrr@10 : 0.3412    ndcg@10 : 0.2015    hit@10 : 0.685    precision@10 : 0.1422\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 23 training [time: 0.50s, train loss: 8.6746]\n",
      "21 Jul 01:39    INFO  epoch 23 evaluating [time: 0.31s, valid_score: 0.334900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1858    mrr@10 : 0.3349    ndcg@10 : 0.2007    hit@10 : 0.6903    precision@10 : 0.1428\n",
      "21 Jul 01:39    INFO  epoch 24 training [time: 0.47s, train loss: 8.4028]\n",
      "21 Jul 01:39    INFO  epoch 24 evaluating [time: 0.31s, valid_score: 0.338400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1889    mrr@10 : 0.3384    ndcg@10 : 0.2032    hit@10 : 0.6925    precision@10 : 0.145\n",
      "21 Jul 01:39    INFO  epoch 25 training [time: 0.47s, train loss: 8.3112]\n",
      "21 Jul 01:39    INFO  epoch 25 evaluating [time: 0.32s, valid_score: 0.342200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1903    mrr@10 : 0.3422    ndcg@10 : 0.2056    hit@10 : 0.6957    precision@10 : 0.1456\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 26 training [time: 0.47s, train loss: 8.1946]\n",
      "21 Jul 01:39    INFO  epoch 26 evaluating [time: 0.32s, valid_score: 0.349200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1909    mrr@10 : 0.3492    ndcg@10 : 0.2075    hit@10 : 0.6999    precision@10 : 0.1472\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 27 training [time: 0.48s, train loss: 8.1182]\n",
      "21 Jul 01:39    INFO  epoch 27 evaluating [time: 0.31s, valid_score: 0.348500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1909    mrr@10 : 0.3485    ndcg@10 : 0.2079    hit@10 : 0.701    precision@10 : 0.1483\n",
      "21 Jul 01:39    INFO  epoch 28 training [time: 0.48s, train loss: 7.9611]\n",
      "21 Jul 01:39    INFO  epoch 28 evaluating [time: 0.31s, valid_score: 0.347800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1895    mrr@10 : 0.3478    ndcg@10 : 0.2069    hit@10 : 0.7094    precision@10 : 0.1473\n",
      "21 Jul 01:39    INFO  epoch 29 training [time: 0.48s, train loss: 7.7703]\n",
      "21 Jul 01:39    INFO  epoch 29 evaluating [time: 0.32s, valid_score: 0.348400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1906    mrr@10 : 0.3484    ndcg@10 : 0.2089    hit@10 : 0.7041    precision@10 : 0.1487\n",
      "21 Jul 01:39    INFO  epoch 30 training [time: 0.47s, train loss: 7.6983]\n",
      "21 Jul 01:39    INFO  epoch 30 evaluating [time: 0.31s, valid_score: 0.349500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1934    mrr@10 : 0.3495    ndcg@10 : 0.21    hit@10 : 0.7105    precision@10 : 0.1502\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 31 training [time: 0.47s, train loss: 7.6426]\n",
      "21 Jul 01:39    INFO  epoch 31 evaluating [time: 0.31s, valid_score: 0.352400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1916    mrr@10 : 0.3524    ndcg@10 : 0.2097    hit@10 : 0.7084    precision@10 : 0.1491\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 32 training [time: 0.47s, train loss: 7.4972]\n",
      "21 Jul 01:39    INFO  epoch 32 evaluating [time: 0.32s, valid_score: 0.354800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1913    mrr@10 : 0.3548    ndcg@10 : 0.2109    hit@10 : 0.7094    precision@10 : 0.1485\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 33 training [time: 0.47s, train loss: 7.4174]\n",
      "21 Jul 01:39    INFO  epoch 33 evaluating [time: 0.32s, valid_score: 0.355000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1943    mrr@10 : 0.355    ndcg@10 : 0.2125    hit@10 : 0.7126    precision@10 : 0.1507\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 34 training [time: 0.47s, train loss: 7.2950]\n",
      "21 Jul 01:39    INFO  epoch 34 evaluating [time: 0.31s, valid_score: 0.350800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1954    mrr@10 : 0.3508    ndcg@10 : 0.2119    hit@10 : 0.7169    precision@10 : 0.1506\n",
      "21 Jul 01:39    INFO  epoch 35 training [time: 0.50s, train loss: 7.1832]\n",
      "21 Jul 01:39    INFO  epoch 35 evaluating [time: 0.35s, valid_score: 0.350500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1913    mrr@10 : 0.3505    ndcg@10 : 0.21    hit@10 : 0.7052    precision@10 : 0.1491\n",
      "21 Jul 01:39    INFO  epoch 36 training [time: 0.47s, train loss: 7.0275]\n",
      "21 Jul 01:39    INFO  epoch 36 evaluating [time: 0.32s, valid_score: 0.356500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1942    mrr@10 : 0.3565    ndcg@10 : 0.2129    hit@10 : 0.7137    precision@10 : 0.1505\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 37 training [time: 0.52s, train loss: 7.0355]\n",
      "21 Jul 01:39    INFO  epoch 37 evaluating [time: 0.29s, valid_score: 0.363600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1965    mrr@10 : 0.3636    ndcg@10 : 0.2172    hit@10 : 0.7158    precision@10 : 0.1526\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 38 training [time: 0.42s, train loss: 6.9350]\n",
      "21 Jul 01:39    INFO  epoch 38 evaluating [time: 0.30s, valid_score: 0.361100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1948    mrr@10 : 0.3611    ndcg@10 : 0.216    hit@10 : 0.7169    precision@10 : 0.1526\n",
      "21 Jul 01:39    INFO  epoch 39 training [time: 0.44s, train loss: 6.8461]\n",
      "21 Jul 01:39    INFO  epoch 39 evaluating [time: 0.32s, valid_score: 0.365200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.197    mrr@10 : 0.3652    ndcg@10 : 0.2171    hit@10 : 0.7147    precision@10 : 0.151\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 40 training [time: 0.47s, train loss: 6.8012]\n",
      "21 Jul 01:39    INFO  epoch 40 evaluating [time: 0.32s, valid_score: 0.366100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.197    mrr@10 : 0.3661    ndcg@10 : 0.2176    hit@10 : 0.7232    precision@10 : 0.1517\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 41 training [time: 0.48s, train loss: 6.6236]\n",
      "21 Jul 01:39    INFO  epoch 41 evaluating [time: 0.34s, valid_score: 0.367800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.198    mrr@10 : 0.3678    ndcg@10 : 0.2191    hit@10 : 0.7232    precision@10 : 0.1533\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 42 training [time: 0.49s, train loss: 6.6195]\n",
      "21 Jul 01:39    INFO  epoch 42 evaluating [time: 0.33s, valid_score: 0.367000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1984    mrr@10 : 0.367    ndcg@10 : 0.2192    hit@10 : 0.7211    precision@10 : 0.1533\n",
      "21 Jul 01:39    INFO  epoch 43 training [time: 0.50s, train loss: 6.5949]\n",
      "21 Jul 01:39    INFO  epoch 43 evaluating [time: 0.31s, valid_score: 0.363000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1992    mrr@10 : 0.363    ndcg@10 : 0.2193    hit@10 : 0.7243    precision@10 : 0.1539\n",
      "21 Jul 01:39    INFO  epoch 44 training [time: 0.49s, train loss: 6.3966]\n",
      "21 Jul 01:39    INFO  epoch 44 evaluating [time: 0.33s, valid_score: 0.360400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2012    mrr@10 : 0.3604    ndcg@10 : 0.2193    hit@10 : 0.7275    precision@10 : 0.1546\n",
      "21 Jul 01:39    INFO  epoch 45 training [time: 0.49s, train loss: 6.3433]\n",
      "21 Jul 01:39    INFO  epoch 45 evaluating [time: 0.33s, valid_score: 0.365800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2013    mrr@10 : 0.3658    ndcg@10 : 0.2203    hit@10 : 0.7328    precision@10 : 0.1545\n",
      "21 Jul 01:39    INFO  epoch 46 training [time: 0.51s, train loss: 6.2873]\n",
      "21 Jul 01:39    INFO  epoch 46 evaluating [time: 0.35s, valid_score: 0.366400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2012    mrr@10 : 0.3664    ndcg@10 : 0.2204    hit@10 : 0.7317    precision@10 : 0.1541\n",
      "21 Jul 01:39    INFO  epoch 47 training [time: 0.52s, train loss: 6.1345]\n",
      "21 Jul 01:39    INFO  epoch 47 evaluating [time: 0.36s, valid_score: 0.368400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3684    ndcg@10 : 0.2236    hit@10 : 0.737    precision@10 : 0.1562\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 48 training [time: 0.52s, train loss: 5.9747]\n",
      "21 Jul 01:39    INFO  epoch 48 evaluating [time: 0.33s, valid_score: 0.369200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3692    ndcg@10 : 0.2234    hit@10 : 0.7402    precision@10 : 0.1561\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 49 training [time: 0.52s, train loss: 6.0464]\n",
      "21 Jul 01:39    INFO  epoch 49 evaluating [time: 0.39s, valid_score: 0.372500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2057    mrr@10 : 0.3725    ndcg@10 : 0.2244    hit@10 : 0.7381    precision@10 : 0.1568\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 50 training [time: 0.52s, train loss: 5.9876]\n",
      "21 Jul 01:39    INFO  epoch 50 evaluating [time: 0.36s, valid_score: 0.367800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2061    mrr@10 : 0.3678    ndcg@10 : 0.2239    hit@10 : 0.7391    precision@10 : 0.1573\n",
      "21 Jul 01:39    INFO  epoch 51 training [time: 0.53s, train loss: 5.9036]\n",
      "21 Jul 01:39    INFO  epoch 51 evaluating [time: 0.39s, valid_score: 0.367000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2063    mrr@10 : 0.367    ndcg@10 : 0.2235    hit@10 : 0.7391    precision@10 : 0.1568\n",
      "21 Jul 01:39    INFO  epoch 52 training [time: 0.52s, train loss: 5.7154]\n",
      "21 Jul 01:39    INFO  epoch 52 evaluating [time: 0.36s, valid_score: 0.363900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2064    mrr@10 : 0.3639    ndcg@10 : 0.2219    hit@10 : 0.7402    precision@10 : 0.1569\n",
      "21 Jul 01:39    INFO  epoch 53 training [time: 0.52s, train loss: 5.6627]\n",
      "21 Jul 01:39    INFO  epoch 53 evaluating [time: 0.38s, valid_score: 0.364500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2071    mrr@10 : 0.3645    ndcg@10 : 0.2236    hit@10 : 0.7423    precision@10 : 0.1584\n",
      "21 Jul 01:39    INFO  epoch 54 training [time: 0.52s, train loss: 5.6610]\n",
      "21 Jul 01:39    INFO  epoch 54 evaluating [time: 0.37s, valid_score: 0.366300]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2051    mrr@10 : 0.3663    ndcg@10 : 0.2231    hit@10 : 0.7349    precision@10 : 0.1575\n",
      "21 Jul 01:39    INFO  epoch 55 training [time: 0.53s, train loss: 5.5598]\n",
      "21 Jul 01:39    INFO  epoch 55 evaluating [time: 0.40s, valid_score: 0.362100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2078    mrr@10 : 0.3621    ndcg@10 : 0.2239    hit@10 : 0.7466    precision@10 : 0.1594\n",
      "21 Jul 01:39    INFO  epoch 56 training [time: 0.53s, train loss: 5.4947]\n",
      "21 Jul 01:39    INFO  epoch 56 evaluating [time: 0.36s, valid_score: 0.365800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2097    mrr@10 : 0.3658    ndcg@10 : 0.2254    hit@10 : 0.7466    precision@10 : 0.16\n",
      "21 Jul 01:39    INFO  epoch 57 training [time: 0.52s, train loss: 5.4664]\n",
      "21 Jul 01:39    INFO  epoch 57 evaluating [time: 0.32s, valid_score: 0.364000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2093    mrr@10 : 0.364    ndcg@10 : 0.225    hit@10 : 0.7434    precision@10 : 0.1598\n",
      "21 Jul 01:39    INFO  epoch 58 training [time: 0.53s, train loss: 5.4129]\n",
      "21 Jul 01:39    INFO  epoch 58 evaluating [time: 0.35s, valid_score: 0.367400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2058    mrr@10 : 0.3674    ndcg@10 : 0.2236    hit@10 : 0.7391    precision@10 : 0.1581\n",
      "21 Jul 01:39    INFO  epoch 59 training [time: 0.51s, train loss: 5.3308]\n",
      "21 Jul 01:39    INFO  epoch 59 evaluating [time: 0.36s, valid_score: 0.364400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2098    mrr@10 : 0.3644    ndcg@10 : 0.2253    hit@10 : 0.7466    precision@10 : 0.1601\n",
      "21 Jul 01:39    INFO  epoch 60 training [time: 0.53s, train loss: 5.3235]\n",
      "21 Jul 01:39    INFO  epoch 60 evaluating [time: 0.34s, valid_score: 0.364000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2117    mrr@10 : 0.364    ndcg@10 : 0.2263    hit@10 : 0.7476    precision@10 : 0.1611\n",
      "21 Jul 01:39    INFO  Finished training, best eval result in epoch 49\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "21 Jul 01:39    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_01-39-06.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('recall@10', 0.2388), ('mrr@10', 0.482), ('ndcg@10', 0.2862), ('hit@10', 0.772), ('precision@10', 0.1914)])\n"
     ]
    }
   ],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer, get_model\n",
    "\n",
    "# configurations initialization\n",
    "config = Config(model='BPR', dataset='ml-100k')\n",
    "\n",
    "# init random seed\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)\n",
    "\n",
    "# dataset creating and filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# model loading and initialization\n",
    "model = BPR(config, train_data._dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "trainer = trainer_class(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10290d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: BPR\n",
      "================================================================================\n",
      "ERROR in rec_eval                                    \n",
      "EXCEPTION                                            \n",
      "<class 'AttributeError'>                             \n",
      "'numpy.random.mtrand.RandomState' object has no attribute 'integers'\n",
      "NODE                                                 \n",
      "0 randint                                            \n",
      "1   Literal{2}\n",
      "2  size =\n",
      "3   len\n",
      "4     array_union\n",
      "5       array_union\n",
      "6         array_union\n",
      "7           Literal{new_ids}\n",
      "8  rng =\n",
      "9   Literal{rng-placeholder}\n",
      "================================================================================\n",
      "  0%|          | 0/6 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.random.mtrand.RandomState' object has no attribute 'integers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m hp \u001b[38;5;241m=\u001b[39m HyperTuning(objective_function\u001b[38;5;241m=\u001b[39mobjective_function, algo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexhaustive\u001b[39m\u001b[38;5;124m'\u001b[39m, early_stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     37\u001b[0m             max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, params_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams.hyper\u001b[39m\u001b[38;5;124m'\u001b[39m, fixed_config_file_list\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# export result to the file\u001b[39;00m\n\u001b[0;32m     42\u001b[0m hp\u001b[38;5;241m.\u001b[39mexport_result(output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyper_example.result\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py:413\u001b[0m, in \u001b[0;36mHyperTuning.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"begin to search the best parameters\"\"\"\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhyperopt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 413\u001b[0m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_hyper()\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py:278\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# Based on existing trials and the domain, use `algo` to probe in\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# new hp points. Save the results of those inspections into\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# `new_trials`. This is the core of `run`, all the rest is just\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# processes orchestration\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m new_trials \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_ids) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(new_trials)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_trials):\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py:124\u001b[0m, in \u001b[0;36mexhaustive_search\u001b[1;34m(new_ids, domain, trials, seed, nbMaxSucessiveFailures)\u001b[0m\n\u001b[0;32m    121\u001b[0m nbSucessiveFailures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m newSample:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# -- sample new specs, idxs, vals\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     idxs, vals \u001b[38;5;241m=\u001b[39m \u001b[43mpyll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_idxs_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_new_ids\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_rng\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     new_result \u001b[38;5;241m=\u001b[39m domain\u001b[38;5;241m.\u001b[39mnew_result()\n\u001b[0;32m    132\u001b[0m     new_misc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(tid\u001b[38;5;241m=\u001b[39mnew_id, cmd\u001b[38;5;241m=\u001b[39mdomain\u001b[38;5;241m.\u001b[39mcmd, workdir\u001b[38;5;241m=\u001b[39mdomain\u001b[38;5;241m.\u001b[39mworkdir)\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\pyll\\base.py:902\u001b[0m, in \u001b[0;36mrec_eval\u001b[1;34m(expr, deepcopy_inputs, memo, max_program_len, memo_gc, print_trace, print_node_on_error)\u001b[0m\n\u001b[0;32m    899\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(_kwargs)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 902\u001b[0m     rval \u001b[38;5;241m=\u001b[39m scope\u001b[38;5;241m.\u001b[39m_impls[node\u001b[38;5;241m.\u001b[39mname](\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_node_on_error:\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\pyll\\stochastic.py:100\u001b[0m, in \u001b[0;36mrandint\u001b[1;34m(low, high, rng, size)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@implicit_stochastic\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@scope\u001b[39m\u001b[38;5;241m.\u001b[39mdefine\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrandint\u001b[39m(low, high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size\u001b[38;5;241m=\u001b[39m()):\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    See np.random.randint documentation.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    rng = random number generator, typically equals np.random.Generator\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegers\u001b[49m(low, high, size)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.random.mtrand.RandomState' object has no attribute 'integers'"
     ]
    }
   ],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "from recbole.model.context_aware_recommender import FM, DeepFM, WideDeep\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "models = {\n",
    "    'BPR': BPR,\n",
    "    # 'LightGCN': LightGCN,\n",
    "    # 'ItemKNN': ItemKNN, \n",
    "    # 'FM': FM,\n",
    "    # 'DeepFM': DeepFM,\n",
    "    # 'WideDeep': WideDeep,\n",
    "    # 'KGCN': KGCN,\n",
    "    # 'KGIN': KGIN,\n",
    "    # 'KGAT': KGAT,\n",
    "    # 'NeuMF': NeuMF\n",
    "    }\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    print(f\"\\033[93mRunning model: {model_name}\\033[0m\")\n",
    "\n",
    "    \n",
    "\n",
    "    config = Config(model=model_name, dataset='ml-100k')\n",
    "\n",
    "    hp = HyperTuning(objective_function=objective_function, algo='exhaustive', early_stop=10,\n",
    "                max_evals=100, params_file='params.hyper', fixed_config_file_list=config)\n",
    "\n",
    "    # run\n",
    "    hp.run()\n",
    "    # export result to the file\n",
    "    hp.export_result(output_file='hyper_example.result')\n",
    "    # print best parameters\n",
    "    print('best params: ', hp.best_params)\n",
    "    # print best result\n",
    "    print('best result: ')\n",
    "    print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = model_class(config, train_data._dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "    trainer = trainer_class(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b7fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mRunning model: BPR\u001b[0m\n",
      "running parameters:                                  \n",
      "{'embedding_size': 64, 'learning_rate': 0.0009845219514902307, 'mlp_hidden_size': '[128,128]'}\n",
      "  0%|          | 0/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:27    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-27-28.pth\u001b[0m\n",
      "\n",
      "2025-07-21 02:27:59,330\tWARNING session.py:91 -- Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \n",
      "2025-07-21 02:27:59,330\tWARNING session.py:97 --   File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Sharjeel Mustafa\\AppData\\Local\\Temp\\ipykernel_3872\\852973914.py\", line 47, in <module>\n",
      "    hp.run()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py\", line 413, in run\n",
      "    fmin(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 553, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 356, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 292, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 170, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\base.py\", line 907, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py\", line 348, in trial\n",
      "    result_dict = self.objective_function(config_dict, self.fixed_config_file_list)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\quick_start\\quick_start.py\", line 223, in objective_function\n",
      "    tune.report(**test_result)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.3896                     \n",
      "current best valid result:                           \n",
      "OrderedDict([('recall@10', 0.2078), ('mrr@10', 0.3896), ('ndcg@10', 0.2294), ('hit@10', 0.7391), ('precision@10', 0.1572)])\n",
      "current test result:                                 \n",
      "OrderedDict([('recall@10', 0.2447), ('mrr@10', 0.4889), ('ndcg@10', 0.2917), ('hit@10', 0.7805), ('precision@10', 0.1949)])\n",
      "running parameters:                                                 \n",
      "{'embedding_size': 128, 'learning_rate': 0.08179343529093307, 'mlp_hidden_size': '[64,64,64]'}\n",
      " 17%|        | 1/6 [00:31<02:38, 31.78s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:28    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-27-59.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 64, 'learning_rate': 0.8723162187044113, 'mlp_hidden_size': '[64,64,64]'}\n",
      " 33%|      | 2/6 [00:55<01:47, 26.75s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:28    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-28-23.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 64, 'learning_rate': 0.05665634889695432, 'mlp_hidden_size': '[128,128]'}\n",
      " 50%|     | 3/6 [01:04<00:56, 18.96s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:28    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-28-32.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 128, 'learning_rate': 0.6768339182018485, 'mlp_hidden_size': '[64,64,64]'}\n",
      " 67%|   | 4/6 [01:23<00:37, 18.84s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:28    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-28-51.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 128, 'learning_rate': 0.5301673241370076, 'mlp_hidden_size': '[128,128]'}\n",
      " 83%| | 5/6 [01:31<00:15, 15.03s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:29    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-28-59.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [01:43<00:00, 17.24s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jul 02:29    INFO  \n",
      "\u001b[1;35mGeneral Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
      "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 2020\u001b[0m\n",
      "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
      "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m C:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\Lib\\site-packages\\recbole\\config\\../dataset_example/ml-100k\u001b[0m\n",
      "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m saved\u001b[0m\n",
      "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\n",
      "\u001b[1;35mTraining Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 300\u001b[0m\n",
      "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
      "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
      "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.001\u001b[0m\n",
      "\u001b[1;36mtrain_neg_sample_args\u001b[0m =\u001b[1;33m {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\u001b[0m\n",
      "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 1\u001b[0m\n",
      "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
      "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
      "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mEvaluation Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\u001b[0m\n",
      "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\u001b[0m\n",
      "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10]\u001b[0m\n",
      "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m MRR@10\u001b[0m\n",
      "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 4096\u001b[0m\n",
      "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mDataset Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
      "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
      "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
      "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m item_id\u001b[0m\n",
      "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
      "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
      "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
      "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
      "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\u001b[0m\n",
      "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
      "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
      "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
      "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
      "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
      "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
      "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
      "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
      "\u001b[1;36mkg_reverse_r\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mentity_kg_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrelation_kg_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\n",
      "\u001b[1;35mOther Hyper Parameters: \n",
      "\u001b[0m\u001b[1;36mworker\u001b[0m = \u001b[1;33m0\u001b[0m\n",
      "\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
      "\u001b[1;36mshuffle\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36menable_amp\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36menable_scaler\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36mtransform\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36membedding_size\u001b[0m = \u001b[1;33m64\u001b[0m\n",
      "\u001b[1;36mnumerical_features\u001b[0m = \u001b[1;33m[]\u001b[0m\n",
      "\u001b[1;36mdiscretization\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.GENERAL\u001b[0m\n",
      "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.PAIRWISE\u001b[0m\n",
      "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
      "\u001b[1;36msingle_spec\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mlocal_rank\u001b[0m = \u001b[1;33m0\u001b[0m\n",
      "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
      "\u001b[1;36mvalid_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
      "\u001b[1;36mtest_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
      "\n",
      "\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best params:  {'embedding_size': 64, 'learning_rate': 0.0009845219514902307, 'mlp_hidden_size': '[128,128]'}\n",
      "best result: \n",
      "{'model': 'BPR', 'best_valid_score': 0.3896, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.2078), ('mrr@10', 0.3896), ('ndcg@10', 0.2294), ('hit@10', 0.7391), ('precision@10', 0.1572)]), 'test_result': OrderedDict([('recall@10', 0.2447), ('mrr@10', 0.4889), ('ndcg@10', 0.2917), ('hit@10', 0.7805), ('precision@10', 0.1949)])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "21 Jul 02:29    INFO  \u001b[1;35mml-100k\u001b[0m\n",
      "\u001b[1;34mThe number of users\u001b[0m: 944\n",
      "\u001b[1;34mAverage actions of users\u001b[0m: 106.04453870625663\n",
      "\u001b[1;34mThe number of items\u001b[0m: 1683\n",
      "\u001b[1;34mAverage actions of items\u001b[0m: 59.45303210463734\n",
      "\u001b[1;34mThe number of inters\u001b[0m: 100000\n",
      "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 93.70575143257098%\n",
      "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'rating', 'timestamp']\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  BPR(\n",
      "  (user_embedding): Embedding(944, 64)\n",
      "  (item_embedding): Embedding(1683, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\u001b[1;34m\n",
      "Trainable parameters\u001b[0m: 168128\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 0 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 27.7207]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 0 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.022600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.0075    mrr@10 : 0.0226    ndcg@10 : 0.0094    hit@10 : 0.0795    precision@10 : 0.0085\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 1 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 27.6127]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 1 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.059900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.0177    mrr@10 : 0.0599    ndcg@10 : 0.0254    hit@10 : 0.176    precision@10 : 0.0223\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 2 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 27.2250]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 2 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.162300]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.0609    mrr@10 : 0.1623    ndcg@10 : 0.0814    hit@10 : 0.3892    precision@10 : 0.068\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 3 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.12s, \u001b[1;34mtrain loss\u001b[0m: 25.6884]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 3 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.25s, \u001b[1;34mvalid_score\u001b[0m: 0.238300]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.099    mrr@10 : 0.2383    ndcg@10 : 0.1225    hit@10 : 0.5069    precision@10 : 0.0931\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 4 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.12s, \u001b[1;34mtrain loss\u001b[0m: 22.1513]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 4 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.253000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1137    mrr@10 : 0.253    ndcg@10 : 0.1364    hit@10 : 0.5419    precision@10 : 0.1034\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 5 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.12s, \u001b[1;34mtrain loss\u001b[0m: 18.0216]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 5 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.25s, \u001b[1;34mvalid_score\u001b[0m: 0.270900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1212    mrr@10 : 0.2709    ndcg@10 : 0.144    hit@10 : 0.5684    precision@10 : 0.1043\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 6 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.12s, \u001b[1;34mtrain loss\u001b[0m: 15.4003]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 6 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.26s, \u001b[1;34mvalid_score\u001b[0m: 0.280800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1258    mrr@10 : 0.2808    ndcg@10 : 0.1488    hit@10 : 0.5716    precision@10 : 0.1056\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 7 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 14.1378]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 7 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.293800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1329    mrr@10 : 0.2938    ndcg@10 : 0.1556    hit@10 : 0.5896    precision@10 : 0.1084\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 8 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 13.3550]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 8 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.306900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.136    mrr@10 : 0.3069    ndcg@10 : 0.1609    hit@10 : 0.5949    precision@10 : 0.1086\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 9 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 12.7709]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 9 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.313900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1432    mrr@10 : 0.3139    ndcg@10 : 0.1668    hit@10 : 0.6151    precision@10 : 0.1128\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 10 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 12.3069]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 10 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.318100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1516    mrr@10 : 0.3181    ndcg@10 : 0.1737    hit@10 : 0.6235    precision@10 : 0.1174\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 11 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 11.8370]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 11 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.323000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1625    mrr@10 : 0.323    ndcg@10 : 0.1813    hit@10 : 0.6458    precision@10 : 0.1233\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 12 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 11.3931]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 12 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.324600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1655    mrr@10 : 0.3246    ndcg@10 : 0.1848    hit@10 : 0.649    precision@10 : 0.1262\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 13 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 11.0161]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 13 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.328700]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1688    mrr@10 : 0.3287    ndcg@10 : 0.1881    hit@10 : 0.6575    precision@10 : 0.13\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 14 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 10.6968]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 14 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.327800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1717    mrr@10 : 0.3278    ndcg@10 : 0.1909    hit@10 : 0.6585    precision@10 : 0.1331\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 15 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 10.3347]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 15 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.329900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1738    mrr@10 : 0.3299    ndcg@10 : 0.1918    hit@10 : 0.6702    precision@10 : 0.1343\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 16 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 10.0525]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 16 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.331100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1778    mrr@10 : 0.3311    ndcg@10 : 0.1931    hit@10 : 0.6755    precision@10 : 0.1361\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 17 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 9.7565]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 17 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.334300]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1799    mrr@10 : 0.3343    ndcg@10 : 0.1967    hit@10 : 0.684    precision@10 : 0.138\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 18 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 9.4517]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 18 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.332600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1817    mrr@10 : 0.3326    ndcg@10 : 0.1965    hit@10 : 0.6946    precision@10 : 0.1387\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 19 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 9.3639]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 19 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.330600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1823    mrr@10 : 0.3306    ndcg@10 : 0.1968    hit@10 : 0.6861    precision@10 : 0.1392\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 20 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 9.1683]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 20 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.333600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1832    mrr@10 : 0.3336    ndcg@10 : 0.1988    hit@10 : 0.6914    precision@10 : 0.1411\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 21 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.9459]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 21 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.332800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1827    mrr@10 : 0.3328    ndcg@10 : 0.1995    hit@10 : 0.685    precision@10 : 0.1422\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 22 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.7272]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 22 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.341200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1838    mrr@10 : 0.3412    ndcg@10 : 0.2015    hit@10 : 0.685    precision@10 : 0.1422\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 23 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 8.6746]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 23 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.334900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1858    mrr@10 : 0.3349    ndcg@10 : 0.2007    hit@10 : 0.6903    precision@10 : 0.1428\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 24 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 8.4028]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 24 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.338400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1889    mrr@10 : 0.3384    ndcg@10 : 0.2032    hit@10 : 0.6925    precision@10 : 0.145\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 25 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 8.3112]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 25 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.342200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1903    mrr@10 : 0.3422    ndcg@10 : 0.2056    hit@10 : 0.6957    precision@10 : 0.1456\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 26 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.1946]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 26 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.349200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1909    mrr@10 : 0.3492    ndcg@10 : 0.2075    hit@10 : 0.6999    precision@10 : 0.1472\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 27 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 8.1182]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 27 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.37s, \u001b[1;34mvalid_score\u001b[0m: 0.348500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1909    mrr@10 : 0.3485    ndcg@10 : 0.2079    hit@10 : 0.701    precision@10 : 0.1483\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 28 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 7.9611]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 28 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.347800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1895    mrr@10 : 0.3478    ndcg@10 : 0.2069    hit@10 : 0.7094    precision@10 : 0.1473\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 29 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.7703]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 29 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.348400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1906    mrr@10 : 0.3484    ndcg@10 : 0.2089    hit@10 : 0.7041    precision@10 : 0.1487\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 30 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 7.6983]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 30 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.349500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1934    mrr@10 : 0.3495    ndcg@10 : 0.21    hit@10 : 0.7105    precision@10 : 0.1502\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 31 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.6426]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 31 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.352400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1916    mrr@10 : 0.3524    ndcg@10 : 0.2097    hit@10 : 0.7084    precision@10 : 0.1491\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 32 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.4972]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 32 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.354800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1913    mrr@10 : 0.3548    ndcg@10 : 0.2109    hit@10 : 0.7094    precision@10 : 0.1485\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 33 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 7.4174]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 33 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.355000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1943    mrr@10 : 0.355    ndcg@10 : 0.2125    hit@10 : 0.7126    precision@10 : 0.1507\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 34 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.2950]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 34 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.350800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1954    mrr@10 : 0.3508    ndcg@10 : 0.2119    hit@10 : 0.7169    precision@10 : 0.1506\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 35 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.1832]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 35 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.350500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1913    mrr@10 : 0.3505    ndcg@10 : 0.21    hit@10 : 0.7052    precision@10 : 0.1491\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 36 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 7.0275]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 36 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.356500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1942    mrr@10 : 0.3565    ndcg@10 : 0.2129    hit@10 : 0.7137    precision@10 : 0.1505\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 37 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 7.0355]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 37 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.363600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1965    mrr@10 : 0.3636    ndcg@10 : 0.2172    hit@10 : 0.7158    precision@10 : 0.1526\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 38 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.9350]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 38 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.361100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1948    mrr@10 : 0.3611    ndcg@10 : 0.216    hit@10 : 0.7169    precision@10 : 0.1526\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 39 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.8461]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 39 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.365200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.197    mrr@10 : 0.3652    ndcg@10 : 0.2171    hit@10 : 0.7147    precision@10 : 0.151\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 40 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.8012]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 40 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.366100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.197    mrr@10 : 0.3661    ndcg@10 : 0.2176    hit@10 : 0.7232    precision@10 : 0.1517\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 41 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.6236]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 41 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.367800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.198    mrr@10 : 0.3678    ndcg@10 : 0.2191    hit@10 : 0.7232    precision@10 : 0.1533\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 42 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.6195]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 42 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.367000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1984    mrr@10 : 0.367    ndcg@10 : 0.2192    hit@10 : 0.7211    precision@10 : 0.1533\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 43 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.5949]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 43 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.363000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1992    mrr@10 : 0.363    ndcg@10 : 0.2193    hit@10 : 0.7243    precision@10 : 0.1539\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 44 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.3966]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 44 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.360400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2012    mrr@10 : 0.3604    ndcg@10 : 0.2193    hit@10 : 0.7275    precision@10 : 0.1546\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 45 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.3433]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 45 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.365800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2013    mrr@10 : 0.3658    ndcg@10 : 0.2203    hit@10 : 0.7328    precision@10 : 0.1545\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 46 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.2873]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 46 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.366400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2012    mrr@10 : 0.3664    ndcg@10 : 0.2204    hit@10 : 0.7317    precision@10 : 0.1541\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 47 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.1345]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 47 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.368400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3684    ndcg@10 : 0.2236    hit@10 : 0.737    precision@10 : 0.1562\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 48 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 5.9747]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 48 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.369200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3692    ndcg@10 : 0.2234    hit@10 : 0.7402    precision@10 : 0.1561\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 49 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.0464]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 49 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.372500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2057    mrr@10 : 0.3725    ndcg@10 : 0.2244    hit@10 : 0.7381    precision@10 : 0.1568\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 50 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.9876]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 50 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.367800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2061    mrr@10 : 0.3678    ndcg@10 : 0.2239    hit@10 : 0.7391    precision@10 : 0.1573\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 51 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.9036]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 51 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.367000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2063    mrr@10 : 0.367    ndcg@10 : 0.2235    hit@10 : 0.7391    precision@10 : 0.1568\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 52 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.7154]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 52 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.363900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2064    mrr@10 : 0.3639    ndcg@10 : 0.2219    hit@10 : 0.7402    precision@10 : 0.1569\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 53 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.6627]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 53 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.364500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2071    mrr@10 : 0.3645    ndcg@10 : 0.2236    hit@10 : 0.7423    precision@10 : 0.1584\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 54 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.6610]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 54 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.366300]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2051    mrr@10 : 0.3663    ndcg@10 : 0.2231    hit@10 : 0.7349    precision@10 : 0.1575\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 55 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.5598]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 55 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.362100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2078    mrr@10 : 0.3621    ndcg@10 : 0.2239    hit@10 : 0.7466    precision@10 : 0.1594\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 56 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.4947]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 56 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.365800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2097    mrr@10 : 0.3658    ndcg@10 : 0.2254    hit@10 : 0.7466    precision@10 : 0.16\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 57 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.4664]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 57 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.364000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2093    mrr@10 : 0.364    ndcg@10 : 0.225    hit@10 : 0.7434    precision@10 : 0.1598\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 58 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.4129]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 58 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.367400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2058    mrr@10 : 0.3674    ndcg@10 : 0.2236    hit@10 : 0.7391    precision@10 : 0.1581\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 59 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.3308]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 59 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.364400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2098    mrr@10 : 0.3644    ndcg@10 : 0.2253    hit@10 : 0.7466    precision@10 : 0.1601\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 60 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 5.3235]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 60 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.364000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2117    mrr@10 : 0.364    ndcg@10 : 0.2263    hit@10 : 0.7476    precision@10 : 0.1611\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  Finished training, best eval result in epoch 49\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "21 Jul 02:29    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('recall@10', 0.2388), ('mrr@10', 0.482), ('ndcg@10', 0.2862), ('hit@10', 0.772), ('precision@10', 0.1914)])\n"
     ]
    }
   ],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "from recbole.model.context_aware_recommender import FM, DeepFM, WideDeep\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "models = {\n",
    "    'BPR': BPR,\n",
    "    # other models commented out\n",
    "}\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    print(f\"\\033[93mRunning model: {model_name}\\033[0m\")\n",
    "\n",
    "    config = Config(model=model_name, dataset='ml-100k')\n",
    "    config_dict = {'model': model_name, 'dataset': 'ml-100k'}\n",
    "    # Initialize hyperparameter tuning for the model\n",
    "    hp = HyperTuning(\n",
    "        objective_function=objective_function,\n",
    "        algo='exhaustive',\n",
    "        early_stop=10,\n",
    "        max_evals=100,\n",
    "        params_file='params.hyper',\n",
    "        fixed_config_file_list=['config.yaml']  # Pass config object here\n",
    "        # fixed_config_file_list=[config]  # Pass config object here\n",
    "    )\n",
    "\n",
    "    # Run the hyperparameter tuning\n",
    "    hp.run()\n",
    "    hp.export_result(output_file='hyper_example.result')\n",
    "\n",
    "    print('best params: ', hp.best_params)\n",
    "    print('best result: ')\n",
    "    print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "    # Now run training with best hyperparameters\n",
    "    \n",
    "\n",
    "    # Seed and logger\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "    logger.info(config)\n",
    "\n",
    "    # Dataset loading and preparation\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # Model initialization\n",
    "    model = model_class(config, train_data._dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # Trainer initialization and training\n",
    "    trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "    trainer = trainer_class(config, model)\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "    # Evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5b1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Time   : 2023/2/13\n",
    "# @Author : Gaowei Zhang\n",
    "# @Email  : zgw2022101006@ruc.edu.cn\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "from recbole.quick_start import run\n",
    "from recbole.utils import list_to_latex\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--model_list\", \"-m\", type=str, default=\"BPR\", help=\"name of models\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dataset\", \"-d\", type=str, default=\"ml-100k\", help=\"name of datasets\"\n",
    "    )\n",
    "    parser.add_argument(\"--config_files\", type=str, default=None, help=\"config files\")\n",
    "    parser.add_argument(\n",
    "        \"--valid_latex\", type=str, default=\"./latex/valid.tex\", help=\"config files\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test_latex\", type=str, default=\"./latex/test.tex\", help=\"config files\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nproc\", type=int, default=1, help=\"the number of process in this group\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ip\", type=str, default=\"localhost\", help=\"the ip of master node\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--port\", type=str, default=\"5678\", help=\"the port of master node\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--world_size\", type=int, default=-1, help=\"total number of jobs\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--group_offset\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"the global rank offset of this group\",\n",
    "    )\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    model_list = args.model_list.strip().split(\",\")\n",
    "    config_file_list = (\n",
    "        args.config_files.strip().split(\" \") if args.config_files else None\n",
    "    )\n",
    "    valid_file = args.valid_latex.strip()\n",
    "    test_file = args.test_latex.strip()\n",
    "\n",
    "    valid_result_list = []\n",
    "    test_result_list = []\n",
    "\n",
    "    run_times = len(model_list)\n",
    "\n",
    "    for idx in range(run_times):\n",
    "        model = model_list[idx]\n",
    "\n",
    "        valid_res_dict = {\"Model\": model}\n",
    "        test_res_dict = {\"Model\": model}\n",
    "        result = run(\n",
    "            model,\n",
    "            args.dataset,\n",
    "            config_file_list=config_file_list,\n",
    "            nproc=args.nproc,\n",
    "            world_size=args.world_size,\n",
    "            ip=args.ip,\n",
    "            port=args.port,\n",
    "            group_offset=args.group_offset,\n",
    "        )\n",
    "        valid_res_dict.update(result[\"best_valid_result\"])\n",
    "        test_res_dict.update(result[\"test_result\"])\n",
    "        bigger_flag = result[\"valid_score_bigger\"]\n",
    "        subset_columns = list(result[\"best_valid_result\"].keys())\n",
    "\n",
    "        valid_result_list.append(valid_res_dict)\n",
    "        test_result_list.append(test_res_dict)\n",
    "\n",
    "    df_valid, tex_valid = list_to_latex(\n",
    "        convert_list=valid_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "    df_test, tex_test = list_to_latex(\n",
    "        convert_list=test_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "\n",
    "    with open(valid_file, \"w\") as f:\n",
    "        f.write(tex_valid)\n",
    "    with open(test_file, \"w\") as f:\n",
    "        f.write(tex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db723740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set values directly\n",
    "    model_list = \"BPR\".strip().split(\",\")\n",
    "    dataset = \"ml-100k\"\n",
    "    config_file_list = None  # or [\"path/to/config1.yaml\", \"path/to/config2.yaml\"]\n",
    "    valid_file = \"./latex/valid.tex\"\n",
    "    test_file = \"./latex/test.tex\"\n",
    "    nproc = 1\n",
    "    ip = \"localhost\"\n",
    "    port = \"5678\"\n",
    "    world_size = -1\n",
    "    group_offset = 0\n",
    "\n",
    "    valid_result_list = []\n",
    "    test_result_list = []\n",
    "\n",
    "    run_times = len(model_list)\n",
    "\n",
    "    for idx in range(run_times):\n",
    "        model = model_list[idx]\n",
    "\n",
    "        valid_res_dict = {\"Model\": model}\n",
    "        test_res_dict = {\"Model\": model}\n",
    "\n",
    "        result = run(\n",
    "            model,\n",
    "            dataset,\n",
    "            config_file_list=config_file_list,\n",
    "            nproc=nproc,\n",
    "            world_size=world_size,\n",
    "            ip=ip,\n",
    "            port=port,\n",
    "            group_offset=group_offset,\n",
    "        )\n",
    "\n",
    "        valid_res_dict.update(result[\"best_valid_result\"])\n",
    "        test_res_dict.update(result[\"test_result\"])\n",
    "        bigger_flag = result[\"valid_score_bigger\"]\n",
    "        subset_columns = list(result[\"best_valid_result\"].keys())\n",
    "\n",
    "        valid_result_list.append(valid_res_dict)\n",
    "        test_result_list.append(test_res_dict)\n",
    "\n",
    "    df_valid, tex_valid = list_to_latex(\n",
    "        convert_list=valid_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "    df_test, tex_test = list_to_latex(\n",
    "        convert_list=test_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "\n",
    "    # with open(valid_file, \"w\") as f:\n",
    "    #     f.write(tex_valid)\n",
    "    # with open(test_file, \"w\") as f:\n",
    "    #     f.write(tex_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b33a48a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mRunning model: BPR\u001b[0m\n",
      "running parameters:                                  \n",
      "{'embedding_size': 128, 'learning_rate': 0.018319142664538036, 'mlp_hidden_size': '[64,64,64]'}\n",
      "  0%|          | 0/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 12:33    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 12:33    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 12:33    INFO  Loading model structure and parameters from ROOT_PATH/log/saved/BPR-Jul-21-2025_12-33-36.pth\u001b[0m\n",
      "\n",
      "2025-07-21 12:33:43,269\tWARNING session.py:91 -- Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \n",
      "2025-07-21 12:33:43,270\tWARNING session.py:97 --   File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Sharjeel Mustafa\\AppData\\Local\\Temp\\ipykernel_6992\\451043146.py\", line 1, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Sharjeel Mustafa\\AppData\\Local\\Temp\\ipykernel_6992\\2417154586.py\", line 39, in main\n",
      "    hp.run()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py\", line 413, in run\n",
      "    fmin(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 553, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 356, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 292, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 170, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\base.py\", line 907, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py\", line 348, in trial\n",
      "    result_dict = self.objective_function(config_dict, self.fixed_config_file_list)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\quick_start\\quick_start.py\", line 223, in objective_function\n",
      "    tune.report(**test_result)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.3111                     \n",
      "current best valid result:                           \n",
      "OrderedDict([('recall@10', 0.1525), ('mrr@10', 0.3111), ('ndcg@10', 0.1673), ('hit@10', 0.6373), ('precision@10', 0.1142)])\n",
      "current test result:                                 \n",
      "OrderedDict([('recall@10', 0.1701), ('mrr@10', 0.3532), ('ndcg@10', 0.1985), ('hit@10', 0.666), ('precision@10', 0.1375)])\n",
      "running parameters:                                                 \n",
      "{'embedding_size': 128, 'learning_rate': 0.14017820619383206, 'mlp_hidden_size': '[128,128]'}\n",
      " 17%|        | 1/6 [00:07<00:36,  7.35s/trial, best loss: -0.3111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 12:33    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 12:33    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 12:33    INFO  Loading model structure and parameters from ROOT_PATH/log/saved/BPR-Jul-21-2025_12-33-43.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 64, 'learning_rate': 0.0033582847266069734, 'mlp_hidden_size': '[128,128]'}\n",
      " 33%|      | 2/6 [00:19<00:41, 10.42s/trial, best loss: -0.3111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 12:33    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 12:33    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 12:34    INFO  Loading model structure and parameters from ROOT_PATH/log/saved/BPR-Jul-21-2025_12-33-56.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.3803                                    \n",
      "current best valid result:                                          \n",
      "OrderedDict([('recall@10', 0.2037), ('mrr@10', 0.3803), ('ndcg@10', 0.2223), ('hit@10', 0.7381), ('precision@10', 0.1541)])\n",
      "current test result:                                                \n",
      "OrderedDict([('recall@10', 0.2428), ('mrr@10', 0.473), ('ndcg@10', 0.2839), ('hit@10', 0.789), ('precision@10', 0.1915)])\n",
      "running parameters:                                                 \n",
      "{'embedding_size': 96, 'learning_rate': 0.17311062924862045, 'mlp_hidden_size': '[64,64,64]'}\n",
      " 50%|     | 3/6 [00:36<00:39, 13.22s/trial, best loss: -0.3803]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 12:34    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 12:34    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 12:34    INFO  Loading model structure and parameters from ROOT_PATH/log/saved/BPR-Jul-21-2025_12-34-12.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 96, 'learning_rate': 0.000851776899960467, 'mlp_hidden_size': '[64,64,64]'}\n",
      " 67%|   | 4/6 [00:44<00:22, 11.35s/trial, best loss: -0.3803]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 12:34    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 12:34    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 12:35    INFO  Loading model structure and parameters from ROOT_PATH/log/saved/BPR-Jul-21-2025_12-34-21.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.3866                                    \n",
      "current best valid result:                                          \n",
      "OrderedDict([('recall@10', 0.2171), ('mrr@10', 0.3866), ('ndcg@10', 0.2329), ('hit@10', 0.7582), ('precision@10', 0.1612)])\n",
      "current test result:                                                \n",
      "OrderedDict([('recall@10', 0.252), ('mrr@10', 0.4973), ('ndcg@10', 0.2973), ('hit@10', 0.7869), ('precision@10', 0.2005)])\n",
      "running parameters:                                                 \n",
      "{'embedding_size': 128, 'learning_rate': 0.04808172242855162, 'mlp_hidden_size': '[128,128]'}\n",
      " 83%| | 5/6 [01:28<00:22, 22.80s/trial, best loss: -0.3866]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 12:35    INFO  Loading model structure and parameters from ROOT_PATH/log/saved/BPR-Jul-21-2025_12-35-04.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [01:34<00:00, 15.77s/trial, best loss: -0.3866]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jul 12:35    INFO  \n",
      "\u001b[1;35mGeneral Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
      "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 2020\u001b[0m\n",
      "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
      "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m C:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\Lib\\site-packages\\recbole\\config\\../dataset_example/ml-100k\u001b[0m\n",
      "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m saved\u001b[0m\n",
      "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\n",
      "\u001b[1;35mTraining Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 300\u001b[0m\n",
      "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
      "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
      "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.000851776899960467\u001b[0m\n",
      "\u001b[1;36mtrain_neg_sample_args\u001b[0m =\u001b[1;33m {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\u001b[0m\n",
      "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 1\u001b[0m\n",
      "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
      "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
      "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mEvaluation Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\u001b[0m\n",
      "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\u001b[0m\n",
      "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10]\u001b[0m\n",
      "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m MRR@10\u001b[0m\n",
      "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 4096\u001b[0m\n",
      "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mDataset Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
      "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
      "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
      "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m item_id\u001b[0m\n",
      "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
      "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
      "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
      "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
      "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\u001b[0m\n",
      "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
      "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
      "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
      "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
      "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
      "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
      "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
      "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
      "\u001b[1;36mkg_reverse_r\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mentity_kg_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrelation_kg_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\n",
      "\u001b[1;35mOther Hyper Parameters: \n",
      "\u001b[0m\u001b[1;36mworker\u001b[0m = \u001b[1;33m0\u001b[0m\n",
      "\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
      "\u001b[1;36mshuffle\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36menable_amp\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36menable_scaler\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36mtransform\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36membedding_size\u001b[0m = \u001b[1;33m96\u001b[0m\n",
      "\u001b[1;36mnumerical_features\u001b[0m = \u001b[1;33m[]\u001b[0m\n",
      "\u001b[1;36mdiscretization\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.GENERAL\u001b[0m\n",
      "\u001b[1;36mmlp_hidden_size\u001b[0m = \u001b[1;33m[64, 64, 64]\u001b[0m\n",
      "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.PAIRWISE\u001b[0m\n",
      "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
      "\u001b[1;36msingle_spec\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mlocal_rank\u001b[0m = \u001b[1;33m0\u001b[0m\n",
      "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
      "\u001b[1;36mvalid_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
      "\u001b[1;36mtest_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
      "\n",
      "\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Params:  {'embedding_size': 96, 'learning_rate': 0.000851776899960467, 'mlp_hidden_size': '[64,64,64]'}\n",
      "Best Result: \n",
      "{'model': 'BPR', 'best_valid_score': 0.3866, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.2171), ('mrr@10', 0.3866), ('ndcg@10', 0.2329), ('hit@10', 0.7582), ('precision@10', 0.1612)]), 'test_result': OrderedDict([('recall@10', 0.252), ('mrr@10', 0.4973), ('ndcg@10', 0.2973), ('hit@10', 0.7869), ('precision@10', 0.2005)])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "21 Jul 12:35    INFO  \u001b[1;35mml-100k\u001b[0m\n",
      "\u001b[1;34mThe number of users\u001b[0m: 944\n",
      "\u001b[1;34mAverage actions of users\u001b[0m: 106.04453870625663\n",
      "\u001b[1;34mThe number of items\u001b[0m: 1683\n",
      "\u001b[1;34mAverage actions of items\u001b[0m: 59.45303210463734\n",
      "\u001b[1;34mThe number of inters\u001b[0m: 100000\n",
      "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 93.70575143257098%\n",
      "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'rating', 'timestamp']\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  BPR(\n",
      "  (user_embedding): Embedding(944, 96)\n",
      "  (item_embedding): Embedding(1683, 96)\n",
      "  (loss): BPRLoss()\n",
      ")\u001b[1;34m\n",
      "Trainable parameters\u001b[0m: 252192\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 0 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 27.7235]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 0 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.017100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.0051    mrr@10 : 0.0171    ndcg@10 : 0.007    hit@10 : 0.0626    precision@10 : 0.0066\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 1 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 27.6263]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 1 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.028100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.008    mrr@10 : 0.0281    ndcg@10 : 0.0115    hit@10 : 0.0976    precision@10 : 0.0109\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 2 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 27.3854]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 2 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.118600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.0365    mrr@10 : 0.1186    ndcg@10 : 0.054    hit@10 : 0.3054    precision@10 : 0.0475\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 3 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 26.5119]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 3 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.225500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.082    mrr@10 : 0.2255    ndcg@10 : 0.1103    hit@10 : 0.4666    precision@10 : 0.0856\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 4 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 24.0562]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 4 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.263400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1035    mrr@10 : 0.2634    ndcg@10 : 0.1342    hit@10 : 0.5228    precision@10 : 0.1006\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 5 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 20.0604]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 5 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.269800]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1155    mrr@10 : 0.2698    ndcg@10 : 0.1425    hit@10 : 0.5419    precision@10 : 0.1057\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 6 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 16.6264]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 6 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.290300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1274    mrr@10 : 0.2903    ndcg@10 : 0.1535    hit@10 : 0.5716    precision@10 : 0.1098\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 7 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 14.7305]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 7 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.302100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1345    mrr@10 : 0.3021    ndcg@10 : 0.1589    hit@10 : 0.5938    precision@10 : 0.1113\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 8 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 13.6511]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 8 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.310800]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.138    mrr@10 : 0.3108    ndcg@10 : 0.1642    hit@10 : 0.5949    precision@10 : 0.1111\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 9 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 12.9078]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 9 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.315600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1501    mrr@10 : 0.3156    ndcg@10 : 0.1712    hit@10 : 0.6225    precision@10 : 0.1175\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 10 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 12.3562]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 10 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.322400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1589    mrr@10 : 0.3224    ndcg@10 : 0.1782    hit@10 : 0.6448    precision@10 : 0.1224\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 11 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 11.8252]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 11 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.324600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1678    mrr@10 : 0.3246    ndcg@10 : 0.1837    hit@10 : 0.6522    precision@10 : 0.1268\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 12 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 11.3297]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 12 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.325400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1682    mrr@10 : 0.3254    ndcg@10 : 0.185    hit@10 : 0.6522    precision@10 : 0.1276\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 13 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 10.9138]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 13 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.331200]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.173    mrr@10 : 0.3312    ndcg@10 : 0.1906    hit@10 : 0.6617    precision@10 : 0.1321\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 14 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 10.5387]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 14 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.333400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1739    mrr@10 : 0.3334    ndcg@10 : 0.1916    hit@10 : 0.6734    precision@10 : 0.1327\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 15 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 10.1585]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 15 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.332500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1777    mrr@10 : 0.3325    ndcg@10 : 0.1935    hit@10 : 0.6734    precision@10 : 0.1344\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 16 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 9.8522]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 16 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.335400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.181    mrr@10 : 0.3354    ndcg@10 : 0.195    hit@10 : 0.6872    precision@10 : 0.1364\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 17 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 9.5095]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 17 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.337500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1821    mrr@10 : 0.3375    ndcg@10 : 0.1973    hit@10 : 0.6893    precision@10 : 0.1375\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 18 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 9.1883]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 18 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.342900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1842    mrr@10 : 0.3429    ndcg@10 : 0.2003    hit@10 : 0.6903    precision@10 : 0.1392\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 19 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 9.0851]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 19 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.339900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1865    mrr@10 : 0.3399    ndcg@10 : 0.2016    hit@10 : 0.6914    precision@10 : 0.1416\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 20 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 8.8733]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 20 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.345300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1877    mrr@10 : 0.3453    ndcg@10 : 0.2035    hit@10 : 0.6925    precision@10 : 0.144\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 21 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.6307]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 21 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.342900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.189    mrr@10 : 0.3429    ndcg@10 : 0.204    hit@10 : 0.701    precision@10 : 0.1453\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 22 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.3906]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 22 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.343900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1889    mrr@10 : 0.3439    ndcg@10 : 0.2045    hit@10 : 0.6935    precision@10 : 0.1452\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 23 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 8.3149]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 23 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.341200]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1916    mrr@10 : 0.3412    ndcg@10 : 0.2053    hit@10 : 0.6925    precision@10 : 0.1455\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 24 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.0496]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 24 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.343100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1934    mrr@10 : 0.3431    ndcg@10 : 0.207    hit@10 : 0.6999    precision@10 : 0.1474\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 25 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.9470]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 25 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.349500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1944    mrr@10 : 0.3495    ndcg@10 : 0.2088    hit@10 : 0.6999    precision@10 : 0.1477\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 26 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 7.8023]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 26 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.351500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1948    mrr@10 : 0.3515    ndcg@10 : 0.2095    hit@10 : 0.7031    precision@10 : 0.148\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 27 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 7.7110]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 27 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.351700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.198    mrr@10 : 0.3517    ndcg@10 : 0.2124    hit@10 : 0.7105    precision@10 : 0.1515\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 28 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 7.5378]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 28 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.352300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.197    mrr@10 : 0.3523    ndcg@10 : 0.2131    hit@10 : 0.7179    precision@10 : 0.1521\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 29 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 7.3622]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 29 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.355300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1973    mrr@10 : 0.3553    ndcg@10 : 0.2129    hit@10 : 0.7169    precision@10 : 0.1509\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 30 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 7.2538]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 30 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.363000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2015    mrr@10 : 0.363    ndcg@10 : 0.2174    hit@10 : 0.7275    precision@10 : 0.1537\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 31 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 7.2105]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 31 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.365100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2035    mrr@10 : 0.3651    ndcg@10 : 0.2181    hit@10 : 0.7306    precision@10 : 0.1541\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 32 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 7.0567]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 32 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.367100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2019    mrr@10 : 0.3671    ndcg@10 : 0.2175    hit@10 : 0.7306    precision@10 : 0.1526\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 33 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.9584]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 33 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.368200]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2026    mrr@10 : 0.3682    ndcg@10 : 0.2195    hit@10 : 0.7328    precision@10 : 0.1542\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 34 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.8372]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 34 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.363900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2021    mrr@10 : 0.3639    ndcg@10 : 0.2179    hit@10 : 0.7317    precision@10 : 0.1526\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 35 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.7181]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 35 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.364000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2019    mrr@10 : 0.364    ndcg@10 : 0.2172    hit@10 : 0.7243    precision@10 : 0.152\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 36 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.5609]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 36 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.360800]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2059    mrr@10 : 0.3608    ndcg@10 : 0.2183    hit@10 : 0.7349    precision@10 : 0.154\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 37 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.5374]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 37 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.367300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2047    mrr@10 : 0.3673    ndcg@10 : 0.2202    hit@10 : 0.7328    precision@10 : 0.1545\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 38 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 6.4516]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 38 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.368700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3687    ndcg@10 : 0.2223    hit@10 : 0.7317    precision@10 : 0.1568\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 39 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 6.3486]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 39 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.371000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2066    mrr@10 : 0.371    ndcg@10 : 0.2235    hit@10 : 0.7328    precision@10 : 0.1561\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 40 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 6.2993]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 40 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.373800]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2089    mrr@10 : 0.3738    ndcg@10 : 0.2249    hit@10 : 0.7402    precision@10 : 0.1567\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 41 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 6.1350]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 41 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.376700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3767    ndcg@10 : 0.2243    hit@10 : 0.7359    precision@10 : 0.156\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 42 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 6.1029]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 42 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.371100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2089    mrr@10 : 0.3711    ndcg@10 : 0.2244    hit@10 : 0.7423    precision@10 : 0.1571\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 43 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 6.0893]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 43 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.371900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2076    mrr@10 : 0.3719    ndcg@10 : 0.2238    hit@10 : 0.7455    precision@10 : 0.1564\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 44 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.8871]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 44 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.373900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2067    mrr@10 : 0.3739    ndcg@10 : 0.2235    hit@10 : 0.7402    precision@10 : 0.156\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 45 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.8360]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 45 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.373600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2096    mrr@10 : 0.3736    ndcg@10 : 0.2251    hit@10 : 0.7487    precision@10 : 0.1569\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 46 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.7747]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 46 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.374100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2113    mrr@10 : 0.3741    ndcg@10 : 0.2263    hit@10 : 0.7529    precision@10 : 0.158\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 47 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.6270]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 47 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.376300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.215    mrr@10 : 0.3763    ndcg@10 : 0.2292    hit@10 : 0.755    precision@10 : 0.1601\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 48 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 5.4439]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 48 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.377500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2187    mrr@10 : 0.3775    ndcg@10 : 0.231    hit@10 : 0.7614    precision@10 : 0.1613\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 49 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.5195]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 49 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.381100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2209    mrr@10 : 0.3811    ndcg@10 : 0.2329    hit@10 : 0.7667    precision@10 : 0.1628\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 50 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.4583]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 50 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.378000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2179    mrr@10 : 0.378    ndcg@10 : 0.2314    hit@10 : 0.7614    precision@10 : 0.1615\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 51 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.3556]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 51 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.375900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2153    mrr@10 : 0.3759    ndcg@10 : 0.2304    hit@10 : 0.755    precision@10 : 0.1608\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 52 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.1845]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 52 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.377400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2143    mrr@10 : 0.3774    ndcg@10 : 0.2308    hit@10 : 0.7529    precision@10 : 0.1603\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 53 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.1409]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 53 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.383100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2162    mrr@10 : 0.3831    ndcg@10 : 0.2329    hit@10 : 0.7519    precision@10 : 0.1616\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 54 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.1167]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 54 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.380100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2148    mrr@10 : 0.3801    ndcg@10 : 0.2319    hit@10 : 0.755    precision@10 : 0.1619\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 55 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.0203]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 55 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.379000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2143    mrr@10 : 0.379    ndcg@10 : 0.2319    hit@10 : 0.7455    precision@10 : 0.1612\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 56 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 4.9590]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 56 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.379800]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2149    mrr@10 : 0.3798    ndcg@10 : 0.2321    hit@10 : 0.7444    precision@10 : 0.1608\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 57 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 4.9237]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 57 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.380300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.214    mrr@10 : 0.3803    ndcg@10 : 0.2312    hit@10 : 0.7444    precision@10 : 0.1592\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 58 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 4.8555]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 58 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.379000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2146    mrr@10 : 0.379    ndcg@10 : 0.2309    hit@10 : 0.7508    precision@10 : 0.1592\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 59 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.7819]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 59 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.380600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2162    mrr@10 : 0.3806    ndcg@10 : 0.231    hit@10 : 0.7508    precision@10 : 0.1596\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 60 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 4.7708]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 60 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.384000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2182    mrr@10 : 0.384    ndcg@10 : 0.2325    hit@10 : 0.7593    precision@10 : 0.1602\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 61 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.6792]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 61 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.384100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2186    mrr@10 : 0.3841    ndcg@10 : 0.2342    hit@10 : 0.7582    precision@10 : 0.1603\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 62 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.6305]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 62 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.388500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2192    mrr@10 : 0.3885    ndcg@10 : 0.2345    hit@10 : 0.7614    precision@10 : 0.1604\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 63 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.5520]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 63 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.392500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2183    mrr@10 : 0.3925    ndcg@10 : 0.236    hit@10 : 0.7497    precision@10 : 0.1606\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 64 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.4430]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 64 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.392500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2168    mrr@10 : 0.3925    ndcg@10 : 0.236    hit@10 : 0.7529    precision@10 : 0.1603\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 65 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 4.4347]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 65 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.391000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2153    mrr@10 : 0.391    ndcg@10 : 0.2352    hit@10 : 0.7529    precision@10 : 0.1614\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 66 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.4044]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 66 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.37s, \u001b[1;34mvalid_score\u001b[0m: 0.390200]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2192    mrr@10 : 0.3902    ndcg@10 : 0.237    hit@10 : 0.7603    precision@10 : 0.1632\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 67 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.4050]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 67 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.392600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2223    mrr@10 : 0.3926    ndcg@10 : 0.2385    hit@10 : 0.7646    precision@10 : 0.1638\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 68 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.2145]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 68 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.385900]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2192    mrr@10 : 0.3859    ndcg@10 : 0.2354    hit@10 : 0.7593    precision@10 : 0.1621\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 69 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 4.2838]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 69 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.388500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.216    mrr@10 : 0.3885    ndcg@10 : 0.2344    hit@10 : 0.7487    precision@10 : 0.1611\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 70 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 4.1832]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 70 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.36s, \u001b[1;34mvalid_score\u001b[0m: 0.387700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2177    mrr@10 : 0.3877    ndcg@10 : 0.2334    hit@10 : 0.7582    precision@10 : 0.161\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 71 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 4.0961]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 71 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.389300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.219    mrr@10 : 0.3893    ndcg@10 : 0.2339    hit@10 : 0.7603    precision@10 : 0.16\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 72 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 4.0543]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 72 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.386700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2184    mrr@10 : 0.3867    ndcg@10 : 0.2339    hit@10 : 0.7593    precision@10 : 0.1609\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 73 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 4.0292]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 73 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.387500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2194    mrr@10 : 0.3875    ndcg@10 : 0.2348    hit@10 : 0.754    precision@10 : 0.1612\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 74 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.9721]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 74 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.392700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2181    mrr@10 : 0.3927    ndcg@10 : 0.2354    hit@10 : 0.7519    precision@10 : 0.1608\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 75 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 3.9138]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 75 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.392800]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2204    mrr@10 : 0.3928    ndcg@10 : 0.2353    hit@10 : 0.7572    precision@10 : 0.1604\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 76 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.7887]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 76 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.389200]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2223    mrr@10 : 0.3892    ndcg@10 : 0.2356    hit@10 : 0.7625    precision@10 : 0.1618\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 77 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 3.8446]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 77 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.391100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2237    mrr@10 : 0.3911    ndcg@10 : 0.2363    hit@10 : 0.7625    precision@10 : 0.1622\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 78 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.7675]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 78 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.392800]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2235    mrr@10 : 0.3928    ndcg@10 : 0.2367    hit@10 : 0.7656    precision@10 : 0.1627\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 79 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.7331]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 79 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.36s, \u001b[1;34mvalid_score\u001b[0m: 0.391400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.221    mrr@10 : 0.3914    ndcg@10 : 0.2349    hit@10 : 0.7603    precision@10 : 0.1601\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 80 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.6267]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 80 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.389000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2205    mrr@10 : 0.389    ndcg@10 : 0.2347    hit@10 : 0.7593    precision@10 : 0.16\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 81 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 3.6350]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 81 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.36s, \u001b[1;34mvalid_score\u001b[0m: 0.390200]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2247    mrr@10 : 0.3902    ndcg@10 : 0.2368    hit@10 : 0.7667    precision@10 : 0.1621\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 82 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.5624]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 82 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.38s, \u001b[1;34mvalid_score\u001b[0m: 0.389700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2271    mrr@10 : 0.3897    ndcg@10 : 0.2387    hit@10 : 0.7752    precision@10 : 0.1644\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 83 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.4774]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 83 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.36s, \u001b[1;34mvalid_score\u001b[0m: 0.389200]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2238    mrr@10 : 0.3892    ndcg@10 : 0.2371    hit@10 : 0.772    precision@10 : 0.1631\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 84 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.4880]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 84 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.390700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2231    mrr@10 : 0.3907    ndcg@10 : 0.2367    hit@10 : 0.7667    precision@10 : 0.1622\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 85 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.4948]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 85 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.387200]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2219    mrr@10 : 0.3872    ndcg@10 : 0.2346    hit@10 : 0.7667    precision@10 : 0.1604\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 86 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.4193]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 86 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.36s, \u001b[1;34mvalid_score\u001b[0m: 0.389700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2207    mrr@10 : 0.3897    ndcg@10 : 0.2337    hit@10 : 0.7625    precision@10 : 0.1597\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 87 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.3888]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 87 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.394000]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.222    mrr@10 : 0.394    ndcg@10 : 0.2353    hit@10 : 0.7635    precision@10 : 0.1594\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 88 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 3.3289]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 88 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.383300]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2219    mrr@10 : 0.3833    ndcg@10 : 0.2324    hit@10 : 0.7614    precision@10 : 0.1601\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 89 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.2138]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 89 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.387600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2226    mrr@10 : 0.3876    ndcg@10 : 0.2339    hit@10 : 0.7678    precision@10 : 0.1607\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 90 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.2511]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 90 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.36s, \u001b[1;34mvalid_score\u001b[0m: 0.386800]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2209    mrr@10 : 0.3868    ndcg@10 : 0.2334    hit@10 : 0.7667    precision@10 : 0.1599\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 91 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.2440]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 91 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.381400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2211    mrr@10 : 0.3814    ndcg@10 : 0.2318    hit@10 : 0.7625    precision@10 : 0.1601\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 92 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.2120]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 92 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.382700]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2218    mrr@10 : 0.3827    ndcg@10 : 0.2319    hit@10 : 0.7688    precision@10 : 0.16\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 93 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.2191]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 93 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.382400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2191    mrr@10 : 0.3824    ndcg@10 : 0.2313    hit@10 : 0.7635    precision@10 : 0.1598\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 94 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 3.1892]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 94 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.378600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2156    mrr@10 : 0.3786    ndcg@10 : 0.2282    hit@10 : 0.7572    precision@10 : 0.1579\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 95 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.0957]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 95 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.380600]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2166    mrr@10 : 0.3806    ndcg@10 : 0.2286    hit@10 : 0.7572    precision@10 : 0.1575\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 96 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 3.0948]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 96 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.379500]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2165    mrr@10 : 0.3795    ndcg@10 : 0.2279    hit@10 : 0.7614    precision@10 : 0.1567\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 97 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 2.9830]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 97 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.377400]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.215    mrr@10 : 0.3774    ndcg@10 : 0.2271    hit@10 : 0.7603    precision@10 : 0.156\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 98 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 2.9836]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;32mepoch 98 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.379100]\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2183    mrr@10 : 0.3791    ndcg@10 : 0.2289    hit@10 : 0.7635    precision@10 : 0.1582\u001b[0m\n",
      "\n",
      "21 Jul 12:35    INFO  Finished training, best eval result in epoch 87\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "21 Jul 12:35    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_12-35-11.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Result:\n",
      "OrderedDict([('recall@10', 0.2536), ('mrr@10', 0.4873), ('ndcg@10', 0.2934), ('hit@10', 0.807), ('precision@10', 0.2002)])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'list_to_latex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 78\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(test_result)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Step 3: Generate and write LaTeX outputs\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m df_valid, tex_valid \u001b[38;5;241m=\u001b[39m \u001b[43mlist_to_latex\u001b[49m(\n\u001b[0;32m     79\u001b[0m     convert_list\u001b[38;5;241m=\u001b[39mvalid_result_list,\n\u001b[0;32m     80\u001b[0m     bigger_flag\u001b[38;5;241m=\u001b[39mbigger_flag,\n\u001b[0;32m     81\u001b[0m     subset_columns\u001b[38;5;241m=\u001b[39msubset_columns,\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     83\u001b[0m df_test, tex_test \u001b[38;5;241m=\u001b[39m list_to_latex(\n\u001b[0;32m     84\u001b[0m     convert_list\u001b[38;5;241m=\u001b[39mtest_result_list,\n\u001b[0;32m     85\u001b[0m     bigger_flag\u001b[38;5;241m=\u001b[39mbigger_flag,\n\u001b[0;32m     86\u001b[0m     subset_columns\u001b[38;5;241m=\u001b[39msubset_columns,\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(valid_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'list_to_latex' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84094791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "from recbole.model.context_aware_recommender import FM, DeepFM, WideDeep\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "def main():\n",
    "    # === Configuration ===\n",
    "    model_list = [\"BPR\"]\n",
    "    dataset_name = \"ml-100k\"\n",
    "    fixed_config_files = [r\"C:\\Users\\Sharjeel Mustafa\\Documents\\Documents\\Academic\\C874\\C874-final-project\\config\\config.yaml\"]\n",
    "    valid_file = \"./latex/valid.tex\"\n",
    "    test_file = \"./latex/test.tex\"\n",
    "\n",
    "    valid_result_list = []\n",
    "    test_result_list = []\n",
    "\n",
    "    for model_name in model_list:\n",
    "        print(f\"\\033[93mRunning model: {model_name}\\033[0m\")\n",
    "\n",
    "        # Step 1: Hyperparameter Tuning\n",
    "        hp = HyperTuning(\n",
    "            objective_function=objective_function,\n",
    "            algo='exhaustive',\n",
    "            early_stop=10,\n",
    "            max_evals=100,\n",
    "            params_file='C:/Users/Sharjeel Mustafa/Documents/Documents/Academic/C874/C874-final-project/config/model.hyper',\n",
    "            fixed_config_file_list=fixed_config_files\n",
    "        )\n",
    "\n",
    "        hp.run()\n",
    "        hp.export_result(output_file='hyper_example.result')\n",
    "\n",
    "        print(\"Best Params: \", hp.best_params)\n",
    "        print(\"Best Result: \")\n",
    "        print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "        # Step 2: Re-train using best parameters\n",
    "        config = Config(model=model_name, dataset=dataset_name, config_dict=hp.best_params)\n",
    "        init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "        init_logger(config)\n",
    "        logger = getLogger()\n",
    "        logger.info(config)\n",
    "\n",
    "        dataset = create_dataset(config)\n",
    "        logger.info(dataset)\n",
    "\n",
    "        train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "        model_class = config['model']\n",
    "        model = config.model_class(config, train_data._dataset).to(config['device'])\n",
    "        logger.info(model)\n",
    "\n",
    "        trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "        trainer = trainer_class(config, model)\n",
    "\n",
    "        best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "        test_result = trainer.evaluate(test_data)\n",
    "\n",
    "        # For LaTeX summary\n",
    "        valid_result_list.append({\"Model\": model_name, **best_valid_result})\n",
    "        test_result_list.append({\"Model\": model_name, **test_result})\n",
    "        bigger_flag = config[\"valid_metric_bigger\"]\n",
    "        subset_columns = list(best_valid_result.keys())\n",
    "\n",
    "        print(\"\\nTest Result:\")\n",
    "        print(test_result)\n",
    "\n",
    "    # Step 3: Generate and write LaTeX outputs\n",
    "    df_valid, tex_valid = list_to_latex(\n",
    "        convert_list=valid_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "    df_test, tex_test = list_to_latex(\n",
    "        convert_list=test_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "\n",
    "    with open(valid_file, \"w\") as f:\n",
    "        f.write(tex_valid)\n",
    "    with open(test_file, \"w\") as f:\n",
    "        f.write(tex_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
