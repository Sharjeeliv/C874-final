{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc650e25",
   "metadata": {},
   "source": [
    "**Collaborative Filtering Approaches**\n",
    "1. Memory-based:    ItemKNN\n",
    "2. Model-based:     BPR, LightGCN\n",
    "3. Context-based:   FM, DeepFM, WideDeep\n",
    "\n",
    "**Content-based Approaches:** TFIDF (Cornac Models)\n",
    "\n",
    "**Knowledge-based Approaches:** KGCN, KGAT, KGIN\n",
    "\n",
    "**Hybrid Systems:** NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9fe9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jul 01:39    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = C:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\Lib\\site-packages\\recbole\\config\\../dataset_example/ml-100k\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = True\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = None\n",
      "relation_kg_num_interval = None\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "21 Jul 01:39    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'rating', 'timestamp']\n",
      "21 Jul 01:39    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "21 Jul 01:39    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "21 Jul 01:39    INFO  BPR(\n",
      "  (user_embedding): Embedding(944, 64)\n",
      "  (item_embedding): Embedding(1683, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 168128\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "21 Jul 01:39    INFO  epoch 0 training [time: 0.58s, train loss: 27.7207]\n",
      "21 Jul 01:39    INFO  epoch 0 evaluating [time: 0.33s, valid_score: 0.022600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.0075    mrr@10 : 0.0226    ndcg@10 : 0.0094    hit@10 : 0.0795    precision@10 : 0.0085\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 1 training [time: 0.48s, train loss: 27.6127]\n",
      "21 Jul 01:39    INFO  epoch 1 evaluating [time: 0.31s, valid_score: 0.059900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.0177    mrr@10 : 0.0599    ndcg@10 : 0.0254    hit@10 : 0.176    precision@10 : 0.0223\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 2 training [time: 0.47s, train loss: 27.2250]\n",
      "21 Jul 01:39    INFO  epoch 2 evaluating [time: 0.31s, valid_score: 0.162300]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.0609    mrr@10 : 0.1623    ndcg@10 : 0.0814    hit@10 : 0.3892    precision@10 : 0.068\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 3 training [time: 0.48s, train loss: 25.6884]\n",
      "21 Jul 01:39    INFO  epoch 3 evaluating [time: 0.31s, valid_score: 0.238300]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.099    mrr@10 : 0.2383    ndcg@10 : 0.1225    hit@10 : 0.5069    precision@10 : 0.0931\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 4 training [time: 0.47s, train loss: 22.1513]\n",
      "21 Jul 01:39    INFO  epoch 4 evaluating [time: 0.31s, valid_score: 0.253000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1137    mrr@10 : 0.253    ndcg@10 : 0.1364    hit@10 : 0.5419    precision@10 : 0.1034\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 5 training [time: 0.47s, train loss: 18.0216]\n",
      "21 Jul 01:39    INFO  epoch 5 evaluating [time: 0.32s, valid_score: 0.270900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1212    mrr@10 : 0.2709    ndcg@10 : 0.144    hit@10 : 0.5684    precision@10 : 0.1043\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 6 training [time: 0.47s, train loss: 15.4003]\n",
      "21 Jul 01:39    INFO  epoch 6 evaluating [time: 0.32s, valid_score: 0.280800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1258    mrr@10 : 0.2808    ndcg@10 : 0.1488    hit@10 : 0.5716    precision@10 : 0.1056\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 7 training [time: 0.47s, train loss: 14.1378]\n",
      "21 Jul 01:39    INFO  epoch 7 evaluating [time: 0.32s, valid_score: 0.293800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1329    mrr@10 : 0.2938    ndcg@10 : 0.1556    hit@10 : 0.5896    precision@10 : 0.1084\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 8 training [time: 0.46s, train loss: 13.3550]\n",
      "21 Jul 01:39    INFO  epoch 8 evaluating [time: 0.29s, valid_score: 0.306900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.136    mrr@10 : 0.3069    ndcg@10 : 0.1609    hit@10 : 0.5949    precision@10 : 0.1086\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 9 training [time: 0.46s, train loss: 12.7709]\n",
      "21 Jul 01:39    INFO  epoch 9 evaluating [time: 0.29s, valid_score: 0.313900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1432    mrr@10 : 0.3139    ndcg@10 : 0.1668    hit@10 : 0.6151    precision@10 : 0.1128\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 10 training [time: 0.46s, train loss: 12.3069]\n",
      "21 Jul 01:39    INFO  epoch 10 evaluating [time: 0.32s, valid_score: 0.318100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1516    mrr@10 : 0.3181    ndcg@10 : 0.1737    hit@10 : 0.6235    precision@10 : 0.1174\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 11 training [time: 0.48s, train loss: 11.8370]\n",
      "21 Jul 01:39    INFO  epoch 11 evaluating [time: 0.31s, valid_score: 0.323000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1625    mrr@10 : 0.323    ndcg@10 : 0.1813    hit@10 : 0.6458    precision@10 : 0.1233\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 12 training [time: 0.48s, train loss: 11.3931]\n",
      "21 Jul 01:39    INFO  epoch 12 evaluating [time: 0.31s, valid_score: 0.324600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1655    mrr@10 : 0.3246    ndcg@10 : 0.1848    hit@10 : 0.649    precision@10 : 0.1262\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 13 training [time: 0.48s, train loss: 11.0161]\n",
      "21 Jul 01:39    INFO  epoch 13 evaluating [time: 0.32s, valid_score: 0.328700]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1688    mrr@10 : 0.3287    ndcg@10 : 0.1881    hit@10 : 0.6575    precision@10 : 0.13\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 14 training [time: 0.48s, train loss: 10.6968]\n",
      "21 Jul 01:39    INFO  epoch 14 evaluating [time: 0.31s, valid_score: 0.327800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1717    mrr@10 : 0.3278    ndcg@10 : 0.1909    hit@10 : 0.6585    precision@10 : 0.1331\n",
      "21 Jul 01:39    INFO  epoch 15 training [time: 0.51s, train loss: 10.3347]\n",
      "21 Jul 01:39    INFO  epoch 15 evaluating [time: 0.32s, valid_score: 0.329900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1738    mrr@10 : 0.3299    ndcg@10 : 0.1918    hit@10 : 0.6702    precision@10 : 0.1343\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 16 training [time: 0.47s, train loss: 10.0525]\n",
      "21 Jul 01:39    INFO  epoch 16 evaluating [time: 0.34s, valid_score: 0.331100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1778    mrr@10 : 0.3311    ndcg@10 : 0.1931    hit@10 : 0.6755    precision@10 : 0.1361\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 17 training [time: 0.47s, train loss: 9.7565]\n",
      "21 Jul 01:39    INFO  epoch 17 evaluating [time: 0.31s, valid_score: 0.334300]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1799    mrr@10 : 0.3343    ndcg@10 : 0.1967    hit@10 : 0.684    precision@10 : 0.138\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 18 training [time: 0.47s, train loss: 9.4517]\n",
      "21 Jul 01:39    INFO  epoch 18 evaluating [time: 0.30s, valid_score: 0.332600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1817    mrr@10 : 0.3326    ndcg@10 : 0.1965    hit@10 : 0.6946    precision@10 : 0.1387\n",
      "21 Jul 01:39    INFO  epoch 19 training [time: 0.46s, train loss: 9.3639]\n",
      "21 Jul 01:39    INFO  epoch 19 evaluating [time: 0.30s, valid_score: 0.330600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1823    mrr@10 : 0.3306    ndcg@10 : 0.1968    hit@10 : 0.6861    precision@10 : 0.1392\n",
      "21 Jul 01:39    INFO  epoch 20 training [time: 0.46s, train loss: 9.1683]\n",
      "21 Jul 01:39    INFO  epoch 20 evaluating [time: 0.32s, valid_score: 0.333600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1832    mrr@10 : 0.3336    ndcg@10 : 0.1988    hit@10 : 0.6914    precision@10 : 0.1411\n",
      "21 Jul 01:39    INFO  epoch 21 training [time: 0.48s, train loss: 8.9459]\n",
      "21 Jul 01:39    INFO  epoch 21 evaluating [time: 0.32s, valid_score: 0.332800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1827    mrr@10 : 0.3328    ndcg@10 : 0.1995    hit@10 : 0.685    precision@10 : 0.1422\n",
      "21 Jul 01:39    INFO  epoch 22 training [time: 0.48s, train loss: 8.7272]\n",
      "21 Jul 01:39    INFO  epoch 22 evaluating [time: 0.31s, valid_score: 0.341200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1838    mrr@10 : 0.3412    ndcg@10 : 0.2015    hit@10 : 0.685    precision@10 : 0.1422\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 23 training [time: 0.50s, train loss: 8.6746]\n",
      "21 Jul 01:39    INFO  epoch 23 evaluating [time: 0.31s, valid_score: 0.334900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1858    mrr@10 : 0.3349    ndcg@10 : 0.2007    hit@10 : 0.6903    precision@10 : 0.1428\n",
      "21 Jul 01:39    INFO  epoch 24 training [time: 0.47s, train loss: 8.4028]\n",
      "21 Jul 01:39    INFO  epoch 24 evaluating [time: 0.31s, valid_score: 0.338400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1889    mrr@10 : 0.3384    ndcg@10 : 0.2032    hit@10 : 0.6925    precision@10 : 0.145\n",
      "21 Jul 01:39    INFO  epoch 25 training [time: 0.47s, train loss: 8.3112]\n",
      "21 Jul 01:39    INFO  epoch 25 evaluating [time: 0.32s, valid_score: 0.342200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1903    mrr@10 : 0.3422    ndcg@10 : 0.2056    hit@10 : 0.6957    precision@10 : 0.1456\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 26 training [time: 0.47s, train loss: 8.1946]\n",
      "21 Jul 01:39    INFO  epoch 26 evaluating [time: 0.32s, valid_score: 0.349200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1909    mrr@10 : 0.3492    ndcg@10 : 0.2075    hit@10 : 0.6999    precision@10 : 0.1472\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 27 training [time: 0.48s, train loss: 8.1182]\n",
      "21 Jul 01:39    INFO  epoch 27 evaluating [time: 0.31s, valid_score: 0.348500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1909    mrr@10 : 0.3485    ndcg@10 : 0.2079    hit@10 : 0.701    precision@10 : 0.1483\n",
      "21 Jul 01:39    INFO  epoch 28 training [time: 0.48s, train loss: 7.9611]\n",
      "21 Jul 01:39    INFO  epoch 28 evaluating [time: 0.31s, valid_score: 0.347800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1895    mrr@10 : 0.3478    ndcg@10 : 0.2069    hit@10 : 0.7094    precision@10 : 0.1473\n",
      "21 Jul 01:39    INFO  epoch 29 training [time: 0.48s, train loss: 7.7703]\n",
      "21 Jul 01:39    INFO  epoch 29 evaluating [time: 0.32s, valid_score: 0.348400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1906    mrr@10 : 0.3484    ndcg@10 : 0.2089    hit@10 : 0.7041    precision@10 : 0.1487\n",
      "21 Jul 01:39    INFO  epoch 30 training [time: 0.47s, train loss: 7.6983]\n",
      "21 Jul 01:39    INFO  epoch 30 evaluating [time: 0.31s, valid_score: 0.349500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1934    mrr@10 : 0.3495    ndcg@10 : 0.21    hit@10 : 0.7105    precision@10 : 0.1502\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 31 training [time: 0.47s, train loss: 7.6426]\n",
      "21 Jul 01:39    INFO  epoch 31 evaluating [time: 0.31s, valid_score: 0.352400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1916    mrr@10 : 0.3524    ndcg@10 : 0.2097    hit@10 : 0.7084    precision@10 : 0.1491\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 32 training [time: 0.47s, train loss: 7.4972]\n",
      "21 Jul 01:39    INFO  epoch 32 evaluating [time: 0.32s, valid_score: 0.354800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1913    mrr@10 : 0.3548    ndcg@10 : 0.2109    hit@10 : 0.7094    precision@10 : 0.1485\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 33 training [time: 0.47s, train loss: 7.4174]\n",
      "21 Jul 01:39    INFO  epoch 33 evaluating [time: 0.32s, valid_score: 0.355000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1943    mrr@10 : 0.355    ndcg@10 : 0.2125    hit@10 : 0.7126    precision@10 : 0.1507\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 34 training [time: 0.47s, train loss: 7.2950]\n",
      "21 Jul 01:39    INFO  epoch 34 evaluating [time: 0.31s, valid_score: 0.350800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1954    mrr@10 : 0.3508    ndcg@10 : 0.2119    hit@10 : 0.7169    precision@10 : 0.1506\n",
      "21 Jul 01:39    INFO  epoch 35 training [time: 0.50s, train loss: 7.1832]\n",
      "21 Jul 01:39    INFO  epoch 35 evaluating [time: 0.35s, valid_score: 0.350500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1913    mrr@10 : 0.3505    ndcg@10 : 0.21    hit@10 : 0.7052    precision@10 : 0.1491\n",
      "21 Jul 01:39    INFO  epoch 36 training [time: 0.47s, train loss: 7.0275]\n",
      "21 Jul 01:39    INFO  epoch 36 evaluating [time: 0.32s, valid_score: 0.356500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1942    mrr@10 : 0.3565    ndcg@10 : 0.2129    hit@10 : 0.7137    precision@10 : 0.1505\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 37 training [time: 0.52s, train loss: 7.0355]\n",
      "21 Jul 01:39    INFO  epoch 37 evaluating [time: 0.29s, valid_score: 0.363600]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1965    mrr@10 : 0.3636    ndcg@10 : 0.2172    hit@10 : 0.7158    precision@10 : 0.1526\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 38 training [time: 0.42s, train loss: 6.9350]\n",
      "21 Jul 01:39    INFO  epoch 38 evaluating [time: 0.30s, valid_score: 0.361100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1948    mrr@10 : 0.3611    ndcg@10 : 0.216    hit@10 : 0.7169    precision@10 : 0.1526\n",
      "21 Jul 01:39    INFO  epoch 39 training [time: 0.44s, train loss: 6.8461]\n",
      "21 Jul 01:39    INFO  epoch 39 evaluating [time: 0.32s, valid_score: 0.365200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.197    mrr@10 : 0.3652    ndcg@10 : 0.2171    hit@10 : 0.7147    precision@10 : 0.151\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 40 training [time: 0.47s, train loss: 6.8012]\n",
      "21 Jul 01:39    INFO  epoch 40 evaluating [time: 0.32s, valid_score: 0.366100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.197    mrr@10 : 0.3661    ndcg@10 : 0.2176    hit@10 : 0.7232    precision@10 : 0.1517\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 41 training [time: 0.48s, train loss: 6.6236]\n",
      "21 Jul 01:39    INFO  epoch 41 evaluating [time: 0.34s, valid_score: 0.367800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.198    mrr@10 : 0.3678    ndcg@10 : 0.2191    hit@10 : 0.7232    precision@10 : 0.1533\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 42 training [time: 0.49s, train loss: 6.6195]\n",
      "21 Jul 01:39    INFO  epoch 42 evaluating [time: 0.33s, valid_score: 0.367000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1984    mrr@10 : 0.367    ndcg@10 : 0.2192    hit@10 : 0.7211    precision@10 : 0.1533\n",
      "21 Jul 01:39    INFO  epoch 43 training [time: 0.50s, train loss: 6.5949]\n",
      "21 Jul 01:39    INFO  epoch 43 evaluating [time: 0.31s, valid_score: 0.363000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.1992    mrr@10 : 0.363    ndcg@10 : 0.2193    hit@10 : 0.7243    precision@10 : 0.1539\n",
      "21 Jul 01:39    INFO  epoch 44 training [time: 0.49s, train loss: 6.3966]\n",
      "21 Jul 01:39    INFO  epoch 44 evaluating [time: 0.33s, valid_score: 0.360400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2012    mrr@10 : 0.3604    ndcg@10 : 0.2193    hit@10 : 0.7275    precision@10 : 0.1546\n",
      "21 Jul 01:39    INFO  epoch 45 training [time: 0.49s, train loss: 6.3433]\n",
      "21 Jul 01:39    INFO  epoch 45 evaluating [time: 0.33s, valid_score: 0.365800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2013    mrr@10 : 0.3658    ndcg@10 : 0.2203    hit@10 : 0.7328    precision@10 : 0.1545\n",
      "21 Jul 01:39    INFO  epoch 46 training [time: 0.51s, train loss: 6.2873]\n",
      "21 Jul 01:39    INFO  epoch 46 evaluating [time: 0.35s, valid_score: 0.366400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2012    mrr@10 : 0.3664    ndcg@10 : 0.2204    hit@10 : 0.7317    precision@10 : 0.1541\n",
      "21 Jul 01:39    INFO  epoch 47 training [time: 0.52s, train loss: 6.1345]\n",
      "21 Jul 01:39    INFO  epoch 47 evaluating [time: 0.36s, valid_score: 0.368400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3684    ndcg@10 : 0.2236    hit@10 : 0.737    precision@10 : 0.1562\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 48 training [time: 0.52s, train loss: 5.9747]\n",
      "21 Jul 01:39    INFO  epoch 48 evaluating [time: 0.33s, valid_score: 0.369200]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3692    ndcg@10 : 0.2234    hit@10 : 0.7402    precision@10 : 0.1561\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 49 training [time: 0.52s, train loss: 6.0464]\n",
      "21 Jul 01:39    INFO  epoch 49 evaluating [time: 0.39s, valid_score: 0.372500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2057    mrr@10 : 0.3725    ndcg@10 : 0.2244    hit@10 : 0.7381    precision@10 : 0.1568\n",
      "21 Jul 01:39    INFO  Saving current: saved\\BPR-Jul-21-2025_01-39-06.pth\n",
      "21 Jul 01:39    INFO  epoch 50 training [time: 0.52s, train loss: 5.9876]\n",
      "21 Jul 01:39    INFO  epoch 50 evaluating [time: 0.36s, valid_score: 0.367800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2061    mrr@10 : 0.3678    ndcg@10 : 0.2239    hit@10 : 0.7391    precision@10 : 0.1573\n",
      "21 Jul 01:39    INFO  epoch 51 training [time: 0.53s, train loss: 5.9036]\n",
      "21 Jul 01:39    INFO  epoch 51 evaluating [time: 0.39s, valid_score: 0.367000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2063    mrr@10 : 0.367    ndcg@10 : 0.2235    hit@10 : 0.7391    precision@10 : 0.1568\n",
      "21 Jul 01:39    INFO  epoch 52 training [time: 0.52s, train loss: 5.7154]\n",
      "21 Jul 01:39    INFO  epoch 52 evaluating [time: 0.36s, valid_score: 0.363900]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2064    mrr@10 : 0.3639    ndcg@10 : 0.2219    hit@10 : 0.7402    precision@10 : 0.1569\n",
      "21 Jul 01:39    INFO  epoch 53 training [time: 0.52s, train loss: 5.6627]\n",
      "21 Jul 01:39    INFO  epoch 53 evaluating [time: 0.38s, valid_score: 0.364500]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2071    mrr@10 : 0.3645    ndcg@10 : 0.2236    hit@10 : 0.7423    precision@10 : 0.1584\n",
      "21 Jul 01:39    INFO  epoch 54 training [time: 0.52s, train loss: 5.6610]\n",
      "21 Jul 01:39    INFO  epoch 54 evaluating [time: 0.37s, valid_score: 0.366300]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2051    mrr@10 : 0.3663    ndcg@10 : 0.2231    hit@10 : 0.7349    precision@10 : 0.1575\n",
      "21 Jul 01:39    INFO  epoch 55 training [time: 0.53s, train loss: 5.5598]\n",
      "21 Jul 01:39    INFO  epoch 55 evaluating [time: 0.40s, valid_score: 0.362100]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2078    mrr@10 : 0.3621    ndcg@10 : 0.2239    hit@10 : 0.7466    precision@10 : 0.1594\n",
      "21 Jul 01:39    INFO  epoch 56 training [time: 0.53s, train loss: 5.4947]\n",
      "21 Jul 01:39    INFO  epoch 56 evaluating [time: 0.36s, valid_score: 0.365800]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2097    mrr@10 : 0.3658    ndcg@10 : 0.2254    hit@10 : 0.7466    precision@10 : 0.16\n",
      "21 Jul 01:39    INFO  epoch 57 training [time: 0.52s, train loss: 5.4664]\n",
      "21 Jul 01:39    INFO  epoch 57 evaluating [time: 0.32s, valid_score: 0.364000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2093    mrr@10 : 0.364    ndcg@10 : 0.225    hit@10 : 0.7434    precision@10 : 0.1598\n",
      "21 Jul 01:39    INFO  epoch 58 training [time: 0.53s, train loss: 5.4129]\n",
      "21 Jul 01:39    INFO  epoch 58 evaluating [time: 0.35s, valid_score: 0.367400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2058    mrr@10 : 0.3674    ndcg@10 : 0.2236    hit@10 : 0.7391    precision@10 : 0.1581\n",
      "21 Jul 01:39    INFO  epoch 59 training [time: 0.51s, train loss: 5.3308]\n",
      "21 Jul 01:39    INFO  epoch 59 evaluating [time: 0.36s, valid_score: 0.364400]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2098    mrr@10 : 0.3644    ndcg@10 : 0.2253    hit@10 : 0.7466    precision@10 : 0.1601\n",
      "21 Jul 01:39    INFO  epoch 60 training [time: 0.53s, train loss: 5.3235]\n",
      "21 Jul 01:39    INFO  epoch 60 evaluating [time: 0.34s, valid_score: 0.364000]\n",
      "21 Jul 01:39    INFO  valid result: \n",
      "recall@10 : 0.2117    mrr@10 : 0.364    ndcg@10 : 0.2263    hit@10 : 0.7476    precision@10 : 0.1611\n",
      "21 Jul 01:39    INFO  Finished training, best eval result in epoch 49\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "21 Jul 01:39    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_01-39-06.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('recall@10', 0.2388), ('mrr@10', 0.482), ('ndcg@10', 0.2862), ('hit@10', 0.772), ('precision@10', 0.1914)])\n"
     ]
    }
   ],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer, get_model\n",
    "\n",
    "# configurations initialization\n",
    "config = Config(model='BPR', dataset='ml-100k')\n",
    "\n",
    "# init random seed\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)\n",
    "\n",
    "# dataset creating and filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# model loading and initialization\n",
    "model = BPR(config, train_data._dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "trainer = trainer_class(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10290d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: BPR\n",
      "================================================================================\n",
      "ERROR in rec_eval                                    \n",
      "EXCEPTION                                            \n",
      "<class 'AttributeError'>                             \n",
      "'numpy.random.mtrand.RandomState' object has no attribute 'integers'\n",
      "NODE                                                 \n",
      "0 randint                                            \n",
      "1   Literal{2}\n",
      "2  size =\n",
      "3   len\n",
      "4     array_union\n",
      "5       array_union\n",
      "6         array_union\n",
      "7           Literal{new_ids}\n",
      "8  rng =\n",
      "9   Literal{rng-placeholder}\n",
      "================================================================================\n",
      "  0%|          | 0/6 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.random.mtrand.RandomState' object has no attribute 'integers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m hp \u001b[38;5;241m=\u001b[39m HyperTuning(objective_function\u001b[38;5;241m=\u001b[39mobjective_function, algo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexhaustive\u001b[39m\u001b[38;5;124m'\u001b[39m, early_stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     37\u001b[0m             max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, params_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams.hyper\u001b[39m\u001b[38;5;124m'\u001b[39m, fixed_config_file_list\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# export result to the file\u001b[39;00m\n\u001b[0;32m     42\u001b[0m hp\u001b[38;5;241m.\u001b[39mexport_result(output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyper_example.result\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py:413\u001b[0m, in \u001b[0;36mHyperTuning.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"begin to search the best parameters\"\"\"\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhyperopt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 413\u001b[0m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_hyper()\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py:278\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# Based on existing trials and the domain, use `algo` to probe in\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# new hp points. Save the results of those inspections into\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# `new_trials`. This is the core of `run`, all the rest is just\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# processes orchestration\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m new_trials \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_ids) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(new_trials)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_trials):\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py:124\u001b[0m, in \u001b[0;36mexhaustive_search\u001b[1;34m(new_ids, domain, trials, seed, nbMaxSucessiveFailures)\u001b[0m\n\u001b[0;32m    121\u001b[0m nbSucessiveFailures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m newSample:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# -- sample new specs, idxs, vals\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     idxs, vals \u001b[38;5;241m=\u001b[39m \u001b[43mpyll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_idxs_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_new_ids\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_rng\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     new_result \u001b[38;5;241m=\u001b[39m domain\u001b[38;5;241m.\u001b[39mnew_result()\n\u001b[0;32m    132\u001b[0m     new_misc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(tid\u001b[38;5;241m=\u001b[39mnew_id, cmd\u001b[38;5;241m=\u001b[39mdomain\u001b[38;5;241m.\u001b[39mcmd, workdir\u001b[38;5;241m=\u001b[39mdomain\u001b[38;5;241m.\u001b[39mworkdir)\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\pyll\\base.py:902\u001b[0m, in \u001b[0;36mrec_eval\u001b[1;34m(expr, deepcopy_inputs, memo, max_program_len, memo_gc, print_trace, print_node_on_error)\u001b[0m\n\u001b[0;32m    899\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(_kwargs)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 902\u001b[0m     rval \u001b[38;5;241m=\u001b[39m scope\u001b[38;5;241m.\u001b[39m_impls[node\u001b[38;5;241m.\u001b[39mname](\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_node_on_error:\n",
      "File \u001b[1;32mc:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\pyll\\stochastic.py:100\u001b[0m, in \u001b[0;36mrandint\u001b[1;34m(low, high, rng, size)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@implicit_stochastic\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@scope\u001b[39m\u001b[38;5;241m.\u001b[39mdefine\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrandint\u001b[39m(low, high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, size\u001b[38;5;241m=\u001b[39m()):\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    See np.random.randint documentation.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    rng = random number generator, typically equals np.random.Generator\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintegers\u001b[49m(low, high, size)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.random.mtrand.RandomState' object has no attribute 'integers'"
     ]
    }
   ],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "from recbole.model.context_aware_recommender import FM, DeepFM, WideDeep\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "models = {\n",
    "    'BPR': BPR,\n",
    "    # 'LightGCN': LightGCN,\n",
    "    # 'ItemKNN': ItemKNN, \n",
    "    # 'FM': FM,\n",
    "    # 'DeepFM': DeepFM,\n",
    "    # 'WideDeep': WideDeep,\n",
    "    # 'KGCN': KGCN,\n",
    "    # 'KGIN': KGIN,\n",
    "    # 'KGAT': KGAT,\n",
    "    # 'NeuMF': NeuMF\n",
    "    }\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    print(f\"\\033[93mRunning model: {model_name}\\033[0m\")\n",
    "\n",
    "    \n",
    "\n",
    "    config = Config(model=model_name, dataset='ml-100k')\n",
    "\n",
    "    hp = HyperTuning(objective_function=objective_function, algo='exhaustive', early_stop=10,\n",
    "                max_evals=100, params_file='params.hyper', fixed_config_file_list=config)\n",
    "\n",
    "    # run\n",
    "    hp.run()\n",
    "    # export result to the file\n",
    "    hp.export_result(output_file='hyper_example.result')\n",
    "    # print best parameters\n",
    "    print('best params: ', hp.best_params)\n",
    "    # print best result\n",
    "    print('best result: ')\n",
    "    print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = model_class(config, train_data._dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "    trainer = trainer_class(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b7fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mRunning model: BPR\u001b[0m\n",
      "running parameters:                                  \n",
      "{'embedding_size': 64, 'learning_rate': 0.0009845219514902307, 'mlp_hidden_size': '[128,128]'}\n",
      "  0%|          | 0/6 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:27    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-27-28.pth\u001b[0m\n",
      "\n",
      "2025-07-21 02:27:59,330\tWARNING session.py:91 -- Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \n",
      "2025-07-21 02:27:59,330\tWARNING session.py:97 --   File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Sharjeel Mustafa\\AppData\\Local\\Temp\\ipykernel_3872\\852973914.py\", line 47, in <module>\n",
      "    hp.run()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py\", line 413, in run\n",
      "    fmin(\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 553, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 356, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 292, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\fmin.py\", line 170, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\hyperopt\\base.py\", line 907, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\hyper_tuning.py\", line 348, in trial\n",
      "    result_dict = self.objective_function(config_dict, self.fixed_config_file_list)\n",
      "  File \"c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\quick_start\\quick_start.py\", line 223, in objective_function\n",
      "    tune.report(**test_result)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current best valid score: 0.3896                     \n",
      "current best valid result:                           \n",
      "OrderedDict([('recall@10', 0.2078), ('mrr@10', 0.3896), ('ndcg@10', 0.2294), ('hit@10', 0.7391), ('precision@10', 0.1572)])\n",
      "current test result:                                 \n",
      "OrderedDict([('recall@10', 0.2447), ('mrr@10', 0.4889), ('ndcg@10', 0.2917), ('hit@10', 0.7805), ('precision@10', 0.1949)])\n",
      "running parameters:                                                 \n",
      "{'embedding_size': 128, 'learning_rate': 0.08179343529093307, 'mlp_hidden_size': '[64,64,64]'}\n",
      " 17%|        | 1/6 [00:31<02:38, 31.78s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:28    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-27-59.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 64, 'learning_rate': 0.8723162187044113, 'mlp_hidden_size': '[64,64,64]'}\n",
      " 33%|      | 2/6 [00:55<01:47, 26.75s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:28    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-28-23.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 64, 'learning_rate': 0.05665634889695432, 'mlp_hidden_size': '[128,128]'}\n",
      " 50%|     | 3/6 [01:04<00:56, 18.96s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:28    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-28-32.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 128, 'learning_rate': 0.6768339182018485, 'mlp_hidden_size': '[64,64,64]'}\n",
      " 67%|   | 4/6 [01:23<00:37, 18.84s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:28    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-28-51.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                 \n",
      "{'embedding_size': 128, 'learning_rate': 0.5301673241370076, 'mlp_hidden_size': '[128,128]'}\n",
      " 83%| | 5/6 [01:31<00:15, 15.03s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "\n",
      "21 Jul 02:29    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-28-59.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [01:43<00:00, 17.24s/trial, best loss: -0.3896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jul 02:29    INFO  \n",
      "\u001b[1;35mGeneral Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
      "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 2020\u001b[0m\n",
      "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
      "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m C:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\Lib\\site-packages\\recbole\\config\\../dataset_example/ml-100k\u001b[0m\n",
      "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m saved\u001b[0m\n",
      "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\n",
      "\u001b[1;35mTraining Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 300\u001b[0m\n",
      "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
      "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
      "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.001\u001b[0m\n",
      "\u001b[1;36mtrain_neg_sample_args\u001b[0m =\u001b[1;33m {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\u001b[0m\n",
      "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 1\u001b[0m\n",
      "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
      "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
      "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mEvaluation Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\u001b[0m\n",
      "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\u001b[0m\n",
      "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10]\u001b[0m\n",
      "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m MRR@10\u001b[0m\n",
      "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 4096\u001b[0m\n",
      "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
      "\n",
      "\u001b[1;35mDataset Hyper Parameters:\n",
      "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
      "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
      "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
      "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m item_id\u001b[0m\n",
      "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
      "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
      "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
      "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
      "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\u001b[0m\n",
      "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m True\u001b[0m\n",
      "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
      "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
      "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
      "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
      "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
      "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
      "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
      "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
      "\u001b[1;36mkg_reverse_r\u001b[0m =\u001b[1;33m False\u001b[0m\n",
      "\u001b[1;36mentity_kg_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mrelation_kg_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m None\u001b[0m\n",
      "\n",
      "\u001b[1;35mOther Hyper Parameters: \n",
      "\u001b[0m\u001b[1;36mworker\u001b[0m = \u001b[1;33m0\u001b[0m\n",
      "\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
      "\u001b[1;36mshuffle\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36menable_amp\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36menable_scaler\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
      "\u001b[1;36mtransform\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36membedding_size\u001b[0m = \u001b[1;33m64\u001b[0m\n",
      "\u001b[1;36mnumerical_features\u001b[0m = \u001b[1;33m[]\u001b[0m\n",
      "\u001b[1;36mdiscretization\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
      "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.GENERAL\u001b[0m\n",
      "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.PAIRWISE\u001b[0m\n",
      "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
      "\u001b[1;36msingle_spec\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
      "\u001b[1;36mlocal_rank\u001b[0m = \u001b[1;33m0\u001b[0m\n",
      "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
      "\u001b[1;36mvalid_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
      "\u001b[1;36mtest_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
      "\n",
      "\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best params:  {'embedding_size': 64, 'learning_rate': 0.0009845219514902307, 'mlp_hidden_size': '[128,128]'}\n",
      "best result: \n",
      "{'model': 'BPR', 'best_valid_score': 0.3896, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('recall@10', 0.2078), ('mrr@10', 0.3896), ('ndcg@10', 0.2294), ('hit@10', 0.7391), ('precision@10', 0.1572)]), 'test_result': OrderedDict([('recall@10', 0.2447), ('mrr@10', 0.4889), ('ndcg@10', 0.2917), ('hit@10', 0.7805), ('precision@10', 0.1949)])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "21 Jul 02:29    INFO  \u001b[1;35mml-100k\u001b[0m\n",
      "\u001b[1;34mThe number of users\u001b[0m: 944\n",
      "\u001b[1;34mAverage actions of users\u001b[0m: 106.04453870625663\n",
      "\u001b[1;34mThe number of items\u001b[0m: 1683\n",
      "\u001b[1;34mAverage actions of items\u001b[0m: 59.45303210463734\n",
      "\u001b[1;34mThe number of inters\u001b[0m: 100000\n",
      "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 93.70575143257098%\n",
      "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id', 'rating', 'timestamp']\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  BPR(\n",
      "  (user_embedding): Embedding(944, 64)\n",
      "  (item_embedding): Embedding(1683, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\u001b[1;34m\n",
      "Trainable parameters\u001b[0m: 168128\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 0 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 27.7207]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 0 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.022600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.0075    mrr@10 : 0.0226    ndcg@10 : 0.0094    hit@10 : 0.0795    precision@10 : 0.0085\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 1 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 27.6127]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 1 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.059900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.0177    mrr@10 : 0.0599    ndcg@10 : 0.0254    hit@10 : 0.176    precision@10 : 0.0223\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 2 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 27.2250]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 2 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.162300]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.0609    mrr@10 : 0.1623    ndcg@10 : 0.0814    hit@10 : 0.3892    precision@10 : 0.068\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 3 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.12s, \u001b[1;34mtrain loss\u001b[0m: 25.6884]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 3 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.25s, \u001b[1;34mvalid_score\u001b[0m: 0.238300]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.099    mrr@10 : 0.2383    ndcg@10 : 0.1225    hit@10 : 0.5069    precision@10 : 0.0931\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 4 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.12s, \u001b[1;34mtrain loss\u001b[0m: 22.1513]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 4 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.253000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1137    mrr@10 : 0.253    ndcg@10 : 0.1364    hit@10 : 0.5419    precision@10 : 0.1034\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 5 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.12s, \u001b[1;34mtrain loss\u001b[0m: 18.0216]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 5 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.25s, \u001b[1;34mvalid_score\u001b[0m: 0.270900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1212    mrr@10 : 0.2709    ndcg@10 : 0.144    hit@10 : 0.5684    precision@10 : 0.1043\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 6 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.12s, \u001b[1;34mtrain loss\u001b[0m: 15.4003]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 6 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.26s, \u001b[1;34mvalid_score\u001b[0m: 0.280800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1258    mrr@10 : 0.2808    ndcg@10 : 0.1488    hit@10 : 0.5716    precision@10 : 0.1056\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 7 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 14.1378]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 7 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.293800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1329    mrr@10 : 0.2938    ndcg@10 : 0.1556    hit@10 : 0.5896    precision@10 : 0.1084\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 8 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 13.3550]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 8 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.306900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.136    mrr@10 : 0.3069    ndcg@10 : 0.1609    hit@10 : 0.5949    precision@10 : 0.1086\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 9 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 12.7709]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 9 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.313900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1432    mrr@10 : 0.3139    ndcg@10 : 0.1668    hit@10 : 0.6151    precision@10 : 0.1128\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 10 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 12.3069]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 10 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.318100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1516    mrr@10 : 0.3181    ndcg@10 : 0.1737    hit@10 : 0.6235    precision@10 : 0.1174\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 11 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 11.8370]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 11 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.323000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1625    mrr@10 : 0.323    ndcg@10 : 0.1813    hit@10 : 0.6458    precision@10 : 0.1233\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 12 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 11.3931]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 12 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.324600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1655    mrr@10 : 0.3246    ndcg@10 : 0.1848    hit@10 : 0.649    precision@10 : 0.1262\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 13 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 11.0161]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 13 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.328700]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1688    mrr@10 : 0.3287    ndcg@10 : 0.1881    hit@10 : 0.6575    precision@10 : 0.13\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 14 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 10.6968]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 14 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.327800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1717    mrr@10 : 0.3278    ndcg@10 : 0.1909    hit@10 : 0.6585    precision@10 : 0.1331\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 15 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 10.3347]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 15 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.329900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1738    mrr@10 : 0.3299    ndcg@10 : 0.1918    hit@10 : 0.6702    precision@10 : 0.1343\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 16 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 10.0525]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 16 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.331100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1778    mrr@10 : 0.3311    ndcg@10 : 0.1931    hit@10 : 0.6755    precision@10 : 0.1361\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 17 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 9.7565]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 17 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.334300]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1799    mrr@10 : 0.3343    ndcg@10 : 0.1967    hit@10 : 0.684    precision@10 : 0.138\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 18 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 9.4517]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 18 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.332600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1817    mrr@10 : 0.3326    ndcg@10 : 0.1965    hit@10 : 0.6946    precision@10 : 0.1387\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 19 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 9.3639]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 19 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.330600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1823    mrr@10 : 0.3306    ndcg@10 : 0.1968    hit@10 : 0.6861    precision@10 : 0.1392\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 20 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 9.1683]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 20 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.333600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1832    mrr@10 : 0.3336    ndcg@10 : 0.1988    hit@10 : 0.6914    precision@10 : 0.1411\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 21 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.9459]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 21 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.332800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1827    mrr@10 : 0.3328    ndcg@10 : 0.1995    hit@10 : 0.685    precision@10 : 0.1422\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 22 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.7272]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 22 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.341200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1838    mrr@10 : 0.3412    ndcg@10 : 0.2015    hit@10 : 0.685    precision@10 : 0.1422\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 23 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 8.6746]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 23 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.334900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1858    mrr@10 : 0.3349    ndcg@10 : 0.2007    hit@10 : 0.6903    precision@10 : 0.1428\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 24 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 8.4028]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 24 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.338400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1889    mrr@10 : 0.3384    ndcg@10 : 0.2032    hit@10 : 0.6925    precision@10 : 0.145\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 25 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 8.3112]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 25 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.342200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1903    mrr@10 : 0.3422    ndcg@10 : 0.2056    hit@10 : 0.6957    precision@10 : 0.1456\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 26 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 8.1946]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 26 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.349200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1909    mrr@10 : 0.3492    ndcg@10 : 0.2075    hit@10 : 0.6999    precision@10 : 0.1472\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 27 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 8.1182]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 27 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.37s, \u001b[1;34mvalid_score\u001b[0m: 0.348500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1909    mrr@10 : 0.3485    ndcg@10 : 0.2079    hit@10 : 0.701    precision@10 : 0.1483\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 28 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 7.9611]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 28 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.347800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1895    mrr@10 : 0.3478    ndcg@10 : 0.2069    hit@10 : 0.7094    precision@10 : 0.1473\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 29 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.7703]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 29 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.348400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1906    mrr@10 : 0.3484    ndcg@10 : 0.2089    hit@10 : 0.7041    precision@10 : 0.1487\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 30 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 7.6983]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 30 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.349500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1934    mrr@10 : 0.3495    ndcg@10 : 0.21    hit@10 : 0.7105    precision@10 : 0.1502\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 31 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.6426]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 31 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.352400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1916    mrr@10 : 0.3524    ndcg@10 : 0.2097    hit@10 : 0.7084    precision@10 : 0.1491\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 32 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.4972]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 32 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.35s, \u001b[1;34mvalid_score\u001b[0m: 0.354800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1913    mrr@10 : 0.3548    ndcg@10 : 0.2109    hit@10 : 0.7094    precision@10 : 0.1485\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 33 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 7.4174]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 33 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.32s, \u001b[1;34mvalid_score\u001b[0m: 0.355000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1943    mrr@10 : 0.355    ndcg@10 : 0.2125    hit@10 : 0.7126    precision@10 : 0.1507\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 34 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.2950]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 34 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.350800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1954    mrr@10 : 0.3508    ndcg@10 : 0.2119    hit@10 : 0.7169    precision@10 : 0.1506\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 35 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 7.1832]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 35 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.350500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1913    mrr@10 : 0.3505    ndcg@10 : 0.21    hit@10 : 0.7052    precision@10 : 0.1491\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 36 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.17s, \u001b[1;34mtrain loss\u001b[0m: 7.0275]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 36 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.34s, \u001b[1;34mvalid_score\u001b[0m: 0.356500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1942    mrr@10 : 0.3565    ndcg@10 : 0.2129    hit@10 : 0.7137    precision@10 : 0.1505\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 37 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 7.0355]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 37 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.363600]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1965    mrr@10 : 0.3636    ndcg@10 : 0.2172    hit@10 : 0.7158    precision@10 : 0.1526\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 38 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.9350]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 38 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.361100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1948    mrr@10 : 0.3611    ndcg@10 : 0.216    hit@10 : 0.7169    precision@10 : 0.1526\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 39 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.8461]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 39 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.365200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.197    mrr@10 : 0.3652    ndcg@10 : 0.2171    hit@10 : 0.7147    precision@10 : 0.151\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 40 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.8012]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 40 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.366100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.197    mrr@10 : 0.3661    ndcg@10 : 0.2176    hit@10 : 0.7232    precision@10 : 0.1517\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 41 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.6236]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 41 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.27s, \u001b[1;34mvalid_score\u001b[0m: 0.367800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.198    mrr@10 : 0.3678    ndcg@10 : 0.2191    hit@10 : 0.7232    precision@10 : 0.1533\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 42 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.6195]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 42 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.367000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1984    mrr@10 : 0.367    ndcg@10 : 0.2192    hit@10 : 0.7211    precision@10 : 0.1533\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 43 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.5949]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 43 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.363000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.1992    mrr@10 : 0.363    ndcg@10 : 0.2193    hit@10 : 0.7243    precision@10 : 0.1539\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 44 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.3966]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 44 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.360400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2012    mrr@10 : 0.3604    ndcg@10 : 0.2193    hit@10 : 0.7275    precision@10 : 0.1546\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 45 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.3433]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 45 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.365800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2013    mrr@10 : 0.3658    ndcg@10 : 0.2203    hit@10 : 0.7328    precision@10 : 0.1545\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 46 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.2873]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 46 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.366400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2012    mrr@10 : 0.3664    ndcg@10 : 0.2204    hit@10 : 0.7317    precision@10 : 0.1541\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 47 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mtrain loss\u001b[0m: 6.1345]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 47 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.368400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3684    ndcg@10 : 0.2236    hit@10 : 0.737    precision@10 : 0.1562\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 48 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 5.9747]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 48 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.369200]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2055    mrr@10 : 0.3692    ndcg@10 : 0.2234    hit@10 : 0.7402    precision@10 : 0.1561\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 49 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mtrain loss\u001b[0m: 6.0464]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 49 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.28s, \u001b[1;34mvalid_score\u001b[0m: 0.372500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2057    mrr@10 : 0.3725    ndcg@10 : 0.2244    hit@10 : 0.7381    precision@10 : 0.1568\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mSaving current\u001b[0m: saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 50 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.9876]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 50 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.367800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2061    mrr@10 : 0.3678    ndcg@10 : 0.2239    hit@10 : 0.7391    precision@10 : 0.1573\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 51 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.9036]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 51 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.367000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2063    mrr@10 : 0.367    ndcg@10 : 0.2235    hit@10 : 0.7391    precision@10 : 0.1568\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 52 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.7154]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 52 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.29s, \u001b[1;34mvalid_score\u001b[0m: 0.363900]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2064    mrr@10 : 0.3639    ndcg@10 : 0.2219    hit@10 : 0.7402    precision@10 : 0.1569\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 53 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.6627]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 53 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.364500]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2071    mrr@10 : 0.3645    ndcg@10 : 0.2236    hit@10 : 0.7423    precision@10 : 0.1584\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 54 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.6610]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 54 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.366300]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2051    mrr@10 : 0.3663    ndcg@10 : 0.2231    hit@10 : 0.7349    precision@10 : 0.1575\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 55 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.5598]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 55 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.30s, \u001b[1;34mvalid_score\u001b[0m: 0.362100]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2078    mrr@10 : 0.3621    ndcg@10 : 0.2239    hit@10 : 0.7466    precision@10 : 0.1594\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 56 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.4947]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 56 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.365800]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2097    mrr@10 : 0.3658    ndcg@10 : 0.2254    hit@10 : 0.7466    precision@10 : 0.16\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 57 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mtrain loss\u001b[0m: 5.4664]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 57 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.364000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2093    mrr@10 : 0.364    ndcg@10 : 0.225    hit@10 : 0.7434    precision@10 : 0.1598\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 58 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.4129]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 58 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.367400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2058    mrr@10 : 0.3674    ndcg@10 : 0.2236    hit@10 : 0.7391    precision@10 : 0.1581\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 59 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.16s, \u001b[1;34mtrain loss\u001b[0m: 5.3308]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 59 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.31s, \u001b[1;34mvalid_score\u001b[0m: 0.364400]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2098    mrr@10 : 0.3644    ndcg@10 : 0.2253    hit@10 : 0.7466    precision@10 : 0.1601\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 60 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.18s, \u001b[1;34mtrain loss\u001b[0m: 5.3235]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;32mepoch 60 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.33s, \u001b[1;34mvalid_score\u001b[0m: 0.364000]\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
      "recall@10 : 0.2117    mrr@10 : 0.364    ndcg@10 : 0.2263    hit@10 : 0.7476    precision@10 : 0.1611\u001b[0m\n",
      "\n",
      "21 Jul 02:29    INFO  Finished training, best eval result in epoch 49\u001b[0m\n",
      "\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "21 Jul 02:29    INFO  Loading model structure and parameters from saved\\BPR-Jul-21-2025_02-29-11.pth\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('recall@10', 0.2388), ('mrr@10', 0.482), ('ndcg@10', 0.2862), ('hit@10', 0.772), ('precision@10', 0.1914)])\n"
     ]
    }
   ],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "from recbole.model.context_aware_recommender import FM, DeepFM, WideDeep\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "models = {\n",
    "    'BPR': BPR,\n",
    "    # other models commented out\n",
    "}\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    print(f\"\\033[93mRunning model: {model_name}\\033[0m\")\n",
    "\n",
    "    config = Config(model=model_name, dataset='ml-100k')\n",
    "    config_dict = {'model': model_name, 'dataset': 'ml-100k'}\n",
    "    # Initialize hyperparameter tuning for the model\n",
    "    hp = HyperTuning(\n",
    "        objective_function=objective_function,\n",
    "        algo='exhaustive',\n",
    "        early_stop=10,\n",
    "        max_evals=100,\n",
    "        params_file='params.hyper',\n",
    "        fixed_config_file_list=['config.yaml']  # Pass config object here\n",
    "        # fixed_config_file_list=[config]  # Pass config object here\n",
    "    )\n",
    "\n",
    "    # Run the hyperparameter tuning\n",
    "    hp.run()\n",
    "    hp.export_result(output_file='hyper_example.result')\n",
    "\n",
    "    print('best params: ', hp.best_params)\n",
    "    print('best result: ')\n",
    "    print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "    # Now run training with best hyperparameters\n",
    "    \n",
    "\n",
    "    # Seed and logger\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "    logger.info(config)\n",
    "\n",
    "    # Dataset loading and preparation\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # Model initialization\n",
    "    model = model_class(config, train_data._dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # Trainer initialization and training\n",
    "    trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "    trainer = trainer_class(config, model)\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "    # Evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53bd4d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "c:\\Users\\Sharjeel Mustafa\\miniconda3\\envs\\recbole\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "21 Jul 02:41    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "21 Jul 02:41    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[4096]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 208\u001b[0m\n\u001b[0;32m    204\u001b[0m     evaluate_recommendations(recommendations, test_interaction, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 180\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    177\u001b[0m train_data, valid_data, test_data \u001b[38;5;241m=\u001b[39m data_preparation(config, dataset)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Build item content matrix (sparse)\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m item_content_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_item_content_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing cosine similarity matrix on item content features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity (sparse matrix) efficiently\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# The output is a sparse matrix, which is memory efficient for large datasets.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 24\u001b[0m, in \u001b[0;36mbuild_item_content_matrix\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_item_content_matrix\u001b[39m(dataset):\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Builds a sparse item-content matrix from the dataset's item features.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    Assumes item genres are in a 'genre' column, pipe-separated.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m        scipy.sparse.csr_matrix: A sparse matrix where rows are items and columns are genres (multi-hot encoded).\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     item_df \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_feat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_df\u001b[49m()\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Extract genres, handling potential missing values\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     raw_genres \u001b[38;5;241m=\u001b[39m item_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_df'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.utils import init_seed, init_logger, get_model\n",
    "from recbole.evaluator import Evaluator\n",
    "from recbole.data.interaction import Interaction\n",
    "import logging # Import logging module for logger\n",
    "\n",
    "\n",
    "def build_item_content_matrix(dataset):\n",
    "    \"\"\"\n",
    "    Builds a sparse item-content matrix from the dataset's item features.\n",
    "    Assumes item genres are in a 'genre' column, pipe-separated.\n",
    "\n",
    "    Args:\n",
    "        dataset: RecBole Dataset object.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: A sparse matrix where rows are items and columns are genres (multi-hot encoded).\n",
    "    \"\"\"\n",
    "    item_df = dataset.item_feat.to_df()\n",
    "\n",
    "    # Extract genres, handling potential missing values\n",
    "    raw_genres = item_df['genre'].fillna('')\n",
    "\n",
    "    # Split genres by \"|\"\n",
    "    genres_list = [g.split('|') for g in raw_genres]\n",
    "\n",
    "    # MultiLabelBinarizer for efficient multi-hot encoding\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    item_content_matrix = mlb.fit_transform(genres_list)  # sparse matrix, shape: (num_items, num_genres)\n",
    "\n",
    "    return item_content_matrix\n",
    "\n",
    "\n",
    "def generate_user_recommendations(train_interaction, similarity_matrix, user_ids, top_k=10):\n",
    "    \"\"\"\n",
    "    Generates top-K item recommendations for specified users based on item-item similarity.\n",
    "\n",
    "    Args:\n",
    "        train_interaction (recbole.data.interaction.Interaction): RecBole Interaction object for training data.\n",
    "        similarity_matrix (scipy.sparse.csr_matrix): Sparse item-item cosine similarity matrix.\n",
    "        user_ids (list or np.ndarray): List or array of user indices for whom to recommend.\n",
    "        top_k (int): The number of top recommendations to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are user IDs and values are lists of recommended item IDs.\n",
    "    \"\"\"\n",
    "    recommendations = dict()\n",
    "    item_num = similarity_matrix.shape[0]\n",
    "\n",
    "    # For sparse matrix indexing efficiency, convert train_interaction to CSR format\n",
    "    # The `user_id_field` and `item_id_field` are important for correctly accessing user-item interactions.\n",
    "    # RecBole internally uses remap_id, so direct integer user_id and item_id are usually 0-indexed.\n",
    "    user_field = train_interaction.user_id_field\n",
    "    item_field = train_interaction.item_id_field\n",
    "\n",
    "    # Create a sparse matrix representation of user-item interactions from train_interaction\n",
    "    # Ensure to use the correct RecBole internal IDs for user and item.\n",
    "    rows = train_interaction[user_field].numpy()\n",
    "    cols = train_interaction[item_field].numpy()\n",
    "    data = np.ones_like(rows, dtype=int) # We just need to mark interaction, value isn't critical\n",
    "    train_coo = sp.coo_matrix((data, (rows, cols)), shape=(len(user_ids), item_num)).tocsr()\n",
    "\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        # Items the user interacted with (row = user)\n",
    "        # Ensure user_id corresponds to the row index in the train_coo matrix.\n",
    "        # If RecBole remaps user IDs, you might need to convert them back or work with remapped IDs.\n",
    "        # Assuming user_ids here are the remapped 0-indexed IDs used internally by RecBole.\n",
    "        if user_id >= train_coo.shape[0]: # Handle cases where a user_id might not be in training data\n",
    "            recommendations[user_id] = []\n",
    "            continue\n",
    "\n",
    "        user_interactions = train_coo[user_id].indices\n",
    "\n",
    "        if len(user_interactions) == 0:\n",
    "            recommendations[user_id] = []\n",
    "            continue\n",
    "\n",
    "        # Sum the similarity scores for these items (sparse vector)\n",
    "        # similarity_matrix[user_interactions] will give a sub-matrix of similarities for interacted items.\n",
    "        # .sum(axis=0) sums these similarities column-wise to get a score for each potential recommendation.\n",
    "        scores = similarity_matrix[user_interactions].sum(axis=0).A1  # .A1 flattens to 1D array\n",
    "\n",
    "        # Remove already interacted items by setting score to -inf\n",
    "        scores[user_interactions] = -np.inf\n",
    "\n",
    "        # Get top-K item indices\n",
    "        # np.argpartition is efficient for finding the k-th smallest/largest element and partitioning.\n",
    "        # Then, sort only those top-k elements.\n",
    "        top_items = np.argpartition(scores, -top_k)[-top_k:]\n",
    "        top_items = top_items[np.argsort(scores[top_items])[::-1]]  # sort top-k descending\n",
    "\n",
    "        recommendations[user_id] = top_items.tolist()\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def evaluate_recommendations(recommendations, test_interaction, k=10):\n",
    "    \"\"\"\n",
    "    Evaluates recommendations using hit rate, precision, and recall.\n",
    "\n",
    "    Args:\n",
    "        recommendations (dict): A dictionary of user_id to list of recommended item_ids.\n",
    "        test_interaction (recbole.data.interaction.Interaction): RecBole Interaction object for test data.\n",
    "        k (int): The number of recommendations considered for evaluation (e.g., Hit Rate@k).\n",
    "    \"\"\"\n",
    "    # RecBole's Evaluator expects a specific format for input (e.g., scores or ranked lists).\n",
    "    # Since we have direct recommendation lists, we'll manually calculate common metrics.\n",
    "    # If you want to use RecBole's Evaluator fully, you'd need to convert `recommendations`\n",
    "    # into a `Prediction` object or similar format that `Evaluator` understands.\n",
    "\n",
    "    hit_rates = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # Map RecBole's internal user/item IDs to your recommendation dictionary's keys\n",
    "    # if they are different (they should be consistent if you used dataset.num('user') for user_ids)\n",
    "    test_user_ids = test_interaction.user_id.numpy()\n",
    "    test_item_ids = test_interaction.item_id.numpy()\n",
    "\n",
    "    # Group true items by user from test_interaction\n",
    "    true_items_by_user = {}\n",
    "    for u, i in zip(test_user_ids, test_item_ids):\n",
    "        true_items_by_user.setdefault(u, []).append(i)\n",
    "\n",
    "    # Iterate through users for whom we have recommendations\n",
    "    for user_id, rec_items in recommendations.items():\n",
    "        if user_id not in true_items_by_user:\n",
    "            # If the user is not in the test set, we skip them for evaluation\n",
    "            # or treat them as having no relevant items for recall (depends on desired behavior).\n",
    "            # For simplicity, we'll skip if no true items are in the test set.\n",
    "            continue\n",
    "\n",
    "        true_items = set(true_items_by_user[user_id])\n",
    "        rec_items_at_k = set(rec_items[:k]) # Consider only top-k recommendations for metrics\n",
    "\n",
    "        hits = len(rec_items_at_k.intersection(true_items))\n",
    "\n",
    "        hit_rate = 1.0 if hits > 0 else 0.0\n",
    "        precision = hits / k if k > 0 else 0.0\n",
    "        recall = hits / len(true_items) if len(true_items) > 0 else 0.0\n",
    "\n",
    "        hit_rates.append(hit_rate)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    if len(hit_rates) > 0:\n",
    "        print(f\"Hit Rate@{k}: {np.mean(hit_rates):.4f}\")\n",
    "        print(f\"Precision@{k}: {np.mean(precisions):.4f}\")\n",
    "        print(f\"Recall@{k}: {np.mean(recalls):.4f}\")\n",
    "    else:\n",
    "        print(\"No users with recommendations found in the test set for evaluation.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the content-based recommendation system.\n",
    "    \"\"\"\n",
    "    # Configure logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Config and seed\n",
    "    # You might want to adjust the 'metrics' in config if you're using RecBole's\n",
    "    # built-in evaluation methods, but for manual calculation, it's not strictly needed here.\n",
    "    config = Config(model='BPR', dataset='ml-100k', config_file_list=[]) # Add config_file_list if you have a config file\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    init_logger(config) # This sets up RecBole's internal logger, which can be different from Python's default logging\n",
    "\n",
    "    # Load and prepare dataset\n",
    "    dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # Build item content matrix (sparse)\n",
    "    item_content_matrix = build_item_content_matrix(dataset)\n",
    "\n",
    "    logger.info(\"Computing cosine similarity matrix on item content features...\")\n",
    "    # Compute cosine similarity (sparse matrix) efficiently\n",
    "    # The output is a sparse matrix, which is memory efficient for large datasets.\n",
    "    similarity_matrix = cosine_similarity(item_content_matrix, dense_output=False)\n",
    "\n",
    "    # Extract user indices (assuming continuous user_id from 0 to n-1)\n",
    "    # RecBole typically remaps user and item IDs to be contiguous 0-indexed integers.\n",
    "    # dataset.num('user') gives the total number of unique users.\n",
    "    user_ids = range(dataset.num('user'))\n",
    "\n",
    "    # Generate recommendations for users\n",
    "    logger.info(\"Generating recommendations...\")\n",
    "    # Get the raw interaction feature data from the training dataset.\n",
    "    # train_data is a DataLoader, train_data._dataset is the Dataset, and .inter_feat is the Interaction object.\n",
    "    train_interaction = train_data._dataset.inter_feat\n",
    "\n",
    "    recommendations = generate_user_recommendations(train_interaction, similarity_matrix, user_ids, top_k=10)\n",
    "\n",
    "    # Evaluate\n",
    "    # Get the raw interaction feature data from the test dataset for evaluation.\n",
    "    test_interaction = test_data._dataset.inter_feat\n",
    "    logger.info(\"Evaluating recommendations...\")\n",
    "    evaluate_recommendations(recommendations, test_interaction, k=10)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
