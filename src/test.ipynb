{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc650e25",
   "metadata": {},
   "source": [
    "**Collaborative Filtering Approaches**\n",
    "1. Memory-based:    ItemKNN\n",
    "2. Model-based:     BPR, LightGCN\n",
    "3. Context-based:   FM, DeepFM, WideDeep\n",
    "\n",
    "**Content-based Approaches:** TFIDF (Cornac Models)\n",
    "\n",
    "**Knowledge-based Approaches:** KGCN, KGAT, KGIN\n",
    "\n",
    "**Hybrid Systems:** NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9fe9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer, get_model\n",
    "\n",
    "# configurations initialization\n",
    "config = Config(model='BPR', dataset='ml-100k')\n",
    "\n",
    "# init random seed\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)\n",
    "\n",
    "# dataset creating and filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# model loading and initialization\n",
    "model = BPR(config, train_data._dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "trainer = trainer_class(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.quick_start import run_recbole\n",
    "\n",
    "run_recbole(model='LightGCN', dataset='ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c29aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10290d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "from recbole.model.context_aware_recommender import FM, DeepFM, WideDeep\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "models = {\n",
    "    'BPR': BPR,\n",
    "    # 'LightGCN': LightGCN,\n",
    "    # 'ItemKNN': ItemKNN, \n",
    "    # 'FM': FM,\n",
    "    # 'DeepFM': DeepFM,\n",
    "    # 'WideDeep': WideDeep,\n",
    "    # 'KGCN': KGCN,\n",
    "    # 'KGIN': KGIN,\n",
    "    # 'KGAT': KGAT,\n",
    "    # 'NeuMF': NeuMF\n",
    "    }\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    print(f\"\\033[93mRunning model: {model_name}\\033[0m\")\n",
    "\n",
    "    \n",
    "\n",
    "    config = Config(model=model_name, dataset='ml-100k')\n",
    "\n",
    "    hp = HyperTuning(objective_function=objective_function, algo='exhaustive', early_stop=10,\n",
    "                max_evals=100, params_file='params.hyper', fixed_config_file_list=config)\n",
    "\n",
    "    # run\n",
    "    hp.run()\n",
    "    # export result to the file\n",
    "    hp.export_result(output_file='hyper_example.result')\n",
    "    # print best parameters\n",
    "    print('best params: ', hp.best_params)\n",
    "    # print best result\n",
    "    print('best result: ')\n",
    "    print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = model_class(config, train_data._dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "    trainer = trainer_class(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "from recbole.model.context_aware_recommender import FM, DeepFM, WideDeep\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "models = {\n",
    "    'BPR': BPR,\n",
    "    # other models commented out\n",
    "}\n",
    "\n",
    "for model_name, model_class in models.items():\n",
    "    print(f\"\\033[93mRunning model: {model_name}\\033[0m\")\n",
    "\n",
    "    config = Config(model=model_name, dataset='ml-100k')\n",
    "    config_dict = {'model': model_name, 'dataset': 'ml-100k'}\n",
    "    # Initialize hyperparameter tuning for the model\n",
    "    hp = HyperTuning(\n",
    "        objective_function=objective_function,\n",
    "        algo='exhaustive',\n",
    "        early_stop=10,\n",
    "        max_evals=100,\n",
    "        params_file='params.hyper',\n",
    "        fixed_config_file_list=['config.yaml']  # Pass config object here\n",
    "        # fixed_config_file_list=[config]  # Pass config object here\n",
    "    )\n",
    "\n",
    "    # Run the hyperparameter tuning\n",
    "    hp.run()\n",
    "    hp.export_result(output_file='hyper_example.result')\n",
    "\n",
    "    print('best params: ', hp.best_params)\n",
    "    print('best result: ')\n",
    "    print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "    # Now run training with best hyperparameters\n",
    "    \n",
    "\n",
    "    # Seed and logger\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "    logger.info(config)\n",
    "\n",
    "    # Dataset loading and preparation\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # Model initialization\n",
    "    model = model_class(config, train_data._dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # Trainer initialization and training\n",
    "    trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "    trainer = trainer_class(config, model)\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "    # Evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Time   : 2023/2/13\n",
    "# @Author : Gaowei Zhang\n",
    "# @Email  : zgw2022101006@ruc.edu.cn\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "from recbole.quick_start import run\n",
    "from recbole.utils import list_to_latex\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--model_list\", \"-m\", type=str, default=\"BPR\", help=\"name of models\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dataset\", \"-d\", type=str, default=\"ml-100k\", help=\"name of datasets\"\n",
    "    )\n",
    "    parser.add_argument(\"--config_files\", type=str, default=None, help=\"config files\")\n",
    "    parser.add_argument(\n",
    "        \"--valid_latex\", type=str, default=\"./latex/valid.tex\", help=\"config files\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test_latex\", type=str, default=\"./latex/test.tex\", help=\"config files\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nproc\", type=int, default=1, help=\"the number of process in this group\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ip\", type=str, default=\"localhost\", help=\"the ip of master node\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--port\", type=str, default=\"5678\", help=\"the port of master node\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--world_size\", type=int, default=-1, help=\"total number of jobs\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--group_offset\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"the global rank offset of this group\",\n",
    "    )\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    model_list = args.model_list.strip().split(\",\")\n",
    "    config_file_list = (\n",
    "        args.config_files.strip().split(\" \") if args.config_files else None\n",
    "    )\n",
    "    valid_file = args.valid_latex.strip()\n",
    "    test_file = args.test_latex.strip()\n",
    "\n",
    "    valid_result_list = []\n",
    "    test_result_list = []\n",
    "\n",
    "    run_times = len(model_list)\n",
    "\n",
    "    for idx in range(run_times):\n",
    "        model = model_list[idx]\n",
    "\n",
    "        valid_res_dict = {\"Model\": model}\n",
    "        test_res_dict = {\"Model\": model}\n",
    "        result = run(\n",
    "            model,\n",
    "            args.dataset,\n",
    "            config_file_list=config_file_list,\n",
    "            nproc=args.nproc,\n",
    "            world_size=args.world_size,\n",
    "            ip=args.ip,\n",
    "            port=args.port,\n",
    "            group_offset=args.group_offset,\n",
    "        )\n",
    "        valid_res_dict.update(result[\"best_valid_result\"])\n",
    "        test_res_dict.update(result[\"test_result\"])\n",
    "        bigger_flag = result[\"valid_score_bigger\"]\n",
    "        subset_columns = list(result[\"best_valid_result\"].keys())\n",
    "\n",
    "        valid_result_list.append(valid_res_dict)\n",
    "        test_result_list.append(test_res_dict)\n",
    "\n",
    "    df_valid, tex_valid = list_to_latex(\n",
    "        convert_list=valid_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "    df_test, tex_test = list_to_latex(\n",
    "        convert_list=test_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "\n",
    "    with open(valid_file, \"w\") as f:\n",
    "        f.write(tex_valid)\n",
    "    with open(test_file, \"w\") as f:\n",
    "        f.write(tex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db723740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set values directly\n",
    "    model_list = \"BPR\".strip().split(\",\")\n",
    "    dataset = \"ml-100k\"\n",
    "    config_file_list = None  # or [\"path/to/config1.yaml\", \"path/to/config2.yaml\"]\n",
    "    valid_file = \"./latex/valid.tex\"\n",
    "    test_file = \"./latex/test.tex\"\n",
    "    nproc = 1\n",
    "    ip = \"localhost\"\n",
    "    port = \"5678\"\n",
    "    world_size = -1\n",
    "    group_offset = 0\n",
    "\n",
    "    valid_result_list = []\n",
    "    test_result_list = []\n",
    "\n",
    "    run_times = len(model_list)\n",
    "\n",
    "    for idx in range(run_times):\n",
    "        model = model_list[idx]\n",
    "\n",
    "        valid_res_dict = {\"Model\": model}\n",
    "        test_res_dict = {\"Model\": model}\n",
    "\n",
    "        result = run(\n",
    "            model,\n",
    "            dataset,\n",
    "            config_file_list=config_file_list,\n",
    "            nproc=nproc,\n",
    "            world_size=world_size,\n",
    "            ip=ip,\n",
    "            port=port,\n",
    "            group_offset=group_offset,\n",
    "        )\n",
    "\n",
    "        valid_res_dict.update(result[\"best_valid_result\"])\n",
    "        test_res_dict.update(result[\"test_result\"])\n",
    "        bigger_flag = result[\"valid_score_bigger\"]\n",
    "        subset_columns = list(result[\"best_valid_result\"].keys())\n",
    "\n",
    "        valid_result_list.append(valid_res_dict)\n",
    "        test_result_list.append(test_res_dict)\n",
    "\n",
    "    df_valid, tex_valid = list_to_latex(\n",
    "        convert_list=valid_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "    df_test, tex_test = list_to_latex(\n",
    "        convert_list=test_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "\n",
    "    # with open(valid_file, \"w\") as f:\n",
    "    #     f.write(tex_valid)\n",
    "    # with open(test_file, \"w\") as f:\n",
    "    #     f.write(tex_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84094791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "\n",
    "from recbole.model.general_recommender import BPR, LightGCN, ItemKNN, NeuMF\n",
    "from recbole.model.context_aware_recommender import FM, DeepFM, WideDeep\n",
    "from recbole.model.knowledge_aware_recommender import KGCN, KGIN, KGAT\n",
    "\n",
    "from recbole.trainer import HyperTuning\n",
    "from recbole.quick_start import objective_function\n",
    "\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "def main():\n",
    "    # === Configuration ===\n",
    "    model_list = [\"BPR\"]\n",
    "    dataset_name = \"ml-100k\"\n",
    "    fixed_config_files = [r\"C:\\Users\\Sharjeel Mustafa\\Documents\\Documents\\Academic\\C874\\C874-final-project\\config\\config.yaml\"]\n",
    "    valid_file = \"./latex/valid.tex\"\n",
    "    test_file = \"./latex/test.tex\"\n",
    "\n",
    "    valid_result_list = []\n",
    "    test_result_list = []\n",
    "\n",
    "    for model_name in model_list:\n",
    "        print(f\"\\033[93mRunning model: {model_name}\\033[0m\")\n",
    "\n",
    "        # Step 1: Hyperparameter Tuning\n",
    "        hp = HyperTuning(\n",
    "            objective_function=objective_function,\n",
    "            algo='exhaustive',\n",
    "            early_stop=10,\n",
    "            max_evals=100,\n",
    "            params_file='C:/Users/Sharjeel Mustafa/Documents/Documents/Academic/C874/C874-final-project/config/model.hyper',\n",
    "            fixed_config_file_list=fixed_config_files\n",
    "        )\n",
    "\n",
    "        hp.run()\n",
    "        hp.export_result(output_file='hyper_example.result')\n",
    "\n",
    "        print(\"Best Params: \", hp.best_params)\n",
    "        print(\"Best Result: \")\n",
    "        print(hp.params2result[hp.params2str(hp.best_params)])\n",
    "\n",
    "        # Step 2: Re-train using best parameters\n",
    "        config = Config(model=model_name, dataset=dataset_name, config_dict=hp.best_params)\n",
    "        init_seed(config[\"seed\"], config[\"reproducibility\"])\n",
    "        init_logger(config)\n",
    "        logger = getLogger()\n",
    "        logger.info(config)\n",
    "\n",
    "        dataset = create_dataset(config)\n",
    "        logger.info(dataset)\n",
    "\n",
    "        train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "        model_class = config['model']\n",
    "        model = config.model_class(config, train_data._dataset).to(config['device'])\n",
    "        logger.info(model)\n",
    "\n",
    "        trainer_class = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])\n",
    "        trainer = trainer_class(config, model)\n",
    "\n",
    "        best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "        test_result = trainer.evaluate(test_data)\n",
    "\n",
    "        # For LaTeX summary\n",
    "        valid_result_list.append({\"Model\": model_name, **best_valid_result})\n",
    "        test_result_list.append({\"Model\": model_name, **test_result})\n",
    "        bigger_flag = config[\"valid_metric_bigger\"]\n",
    "        subset_columns = list(best_valid_result.keys())\n",
    "\n",
    "        print(\"\\nTest Result:\")\n",
    "        print(test_result)\n",
    "\n",
    "    # Step 3: Generate and write LaTeX outputs\n",
    "    df_valid, tex_valid = list_to_latex(\n",
    "        convert_list=valid_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "    df_test, tex_test = list_to_latex(\n",
    "        convert_list=test_result_list,\n",
    "        bigger_flag=bigger_flag,\n",
    "        subset_columns=subset_columns,\n",
    "    )\n",
    "\n",
    "    with open(valid_file, \"w\") as f:\n",
    "        f.write(tex_valid)\n",
    "    with open(test_file, \"w\") as f:\n",
    "        f.write(tex_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
