'dropout_prob:': 0.0
'embedding_size:': 128
'learning_rate:': 0.0001
'mlp_hidden_size:': '[128,128]'
'n_layers:': 1
'reg_weight:': 1.0e-06
